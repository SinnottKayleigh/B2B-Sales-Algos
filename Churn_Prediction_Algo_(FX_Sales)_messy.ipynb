{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXIY29+GVPtc5FUbgQHB9a"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "# Set up Faker\n",
        "fake = Faker('en_GB')\n",
        "\n",
        "# Define lists for additional randomization\n",
        "industries = [\n",
        "    'Finance', 'Tech', 'Food & Beverage',\n",
        "    'Retail', 'Travel'\n",
        "]\n",
        "\n",
        "international_regions = [\n",
        "    'Europe', 'North America', 'Asia Pacific',\n",
        "    'Middle East', 'Developed Markets'\n",
        "]\n",
        "\n",
        "def generate_sales_data(num_entries=200):\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_entries):\n",
        "        # Company details\n",
        "        company_name = fake.company()\n",
        "        hq_location = random.choice([\n",
        "            'London', 'Manchester', 'Edinburgh',\n",
        "            'Birmingham', 'Bristol', 'Leeds'\n",
        "        ])\n",
        "        industry = random.choice(industries)\n",
        "\n",
        "        # Financial details\n",
        "        annual_revenue = round(np.random.uniform(5, 500), 2)\n",
        "        company_size = random.choice([\n",
        "            '50-100 employees',\n",
        "            '100-250 employees',\n",
        "            '250-500 employees',\n",
        "            '500-1000 employees'\n",
        "        ])\n",
        "        international_exposure = random.choice(international_regions)\n",
        "\n",
        "        # FX details\n",
        "        fx_volume = round(np.random.uniform(1, 50), 2)\n",
        "        lead_score = random.randint(50, 95)\n",
        "\n",
        "        # Contact details\n",
        "        first_name = fake.first_name()\n",
        "        last_name = fake.last_name()\n",
        "        contact_name = f\"{first_name} {last_name}\"\n",
        "        email = f\"{first_name.lower()}.{last_name.lower()}@{company_name.replace(' ', '').lower()}.co.uk\"\n",
        "\n",
        "        # Customize contact positions based on industry\n",
        "        contact_positions = {\n",
        "            'Finance': ['CFO', 'Financial Director', 'Head of Treasury', 'Finance Manager'],\n",
        "            'Tech': ['CTO', 'Head of Operations', 'Chief Innovation Officer', 'IT Director'],\n",
        "            'Food & Beverage': ['Operations Director', 'Supply Chain Manager', 'Procurement Head', 'CEO'],\n",
        "            'Retail': ['Retail Operations Director', 'Procurement Manager', 'Supply Chain Director', 'Commercial Director'],\n",
        "            'Travel': ['Operations Director', 'Chief Commercial Officer', 'Head of International Operations', 'Strategy Director']\n",
        "        }\n",
        "\n",
        "        contact_position = random.choice(contact_positions[industry])\n",
        "        phone_number = fake.phone_number()\n",
        "\n",
        "        # Create entry\n",
        "        entry = {\n",
        "            'Company Name': company_name,\n",
        "            'Company HQ': hq_location,\n",
        "            'Industry': industry,\n",
        "            'Annual Revenue (£M)': annual_revenue,\n",
        "            'Company Size': company_size,\n",
        "            'International Exposure': international_exposure,\n",
        "            'Current FX Volume (£M)': fx_volume,\n",
        "            'Potential Lead Score': lead_score,\n",
        "            'Contact Name': contact_name,\n",
        "            'Contact Email': email,\n",
        "            'Contact Position': contact_position,\n",
        "            'Phone Number': phone_number\n",
        "        }\n",
        "\n",
        "        data.append(entry)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Generate and save the dataset\n",
        "sales_data = generate_sales_data()\n",
        "\n",
        "# Save to CSV (optional)\n",
        "sales_data.to_csv('fx_sales_leads.csv', index=False)\n",
        "\n",
        "# Display first few rows\n",
        "print(sales_data.head())\n",
        "\n",
        "# Optional: Show industry distribution\n",
        "print(\"\\nIndustry Distribution:\")\n",
        "print(sales_data['Industry'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "sTOJssjYV-As",
        "outputId": "1930e76f-f9ce-49a4-fddd-5087cf91cad8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'faker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b4cb6e6bf3db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfaker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Set up the Faker instance\n",
        "fake = Faker('en_GB')\n",
        "\n",
        "def generate_fx_sales_data(num_entries=200):\n",
        "    data = []\n",
        "\n",
        "    # Define lists for consistent data generation\n",
        "    uk_cities = [\n",
        "        'London', 'Manchester', 'Birmingham', 'Edinburgh',\n",
        "        'Bristol', 'Leeds', 'Glasgow', 'Cambridge', 'Oxford'\n",
        "    ]\n",
        "\n",
        "    industries = [\n",
        "        'Manufacturing', 'Technology', 'Retail',\n",
        "        'Professional Services', 'Healthcare',\n",
        "        'Consumer Goods', 'Energy', 'Media'\n",
        "    ]\n",
        "\n",
        "    overseas_markets = [\n",
        "        'European Union', 'North America', 'Asia Pacific',\n",
        "        'Western Europe', 'Nordics', 'Australia/NZ'\n",
        "    ]\n",
        "\n",
        "    currencies_traded = ['EUR', 'USD', 'JPY', 'CHF', 'AUD', 'CAD', 'SEK', 'NOK']\n",
        "\n",
        "    for _ in range(num_entries):\n",
        "        # Company Details\n",
        "        company_name = fake.company()\n",
        "        hq_location = random.choice(uk_cities)\n",
        "        industry = random.choice(industries)\n",
        "        year_established = random.randint(1950, 2015)\n",
        "\n",
        "        # Financial Metrics\n",
        "        annual_revenue = round(random.uniform(10, 500), 2)  # In millions GBP\n",
        "        market_cap = round(annual_revenue * random.uniform(1.5, 4), 2)  # In millions GBP\n",
        "        employees = random.choice([50, 100, 250, 500, 1000, 2000, 5000])\n",
        "\n",
        "        # FX Trading Profile\n",
        "        monthly_fx_volume = round(random.uniform(1, 50), 2)  # In millions GBP\n",
        "        primary_currency_pair = random.choice(currencies_traded) + '/GBP'\n",
        "        num_currency_pairs_traded = random.randint(1, 6)\n",
        "\n",
        "        # International Exposure\n",
        "        primary_overseas_market = random.choice(overseas_markets)\n",
        "        num_overseas_subsidiaries = random.randint(1, 8)\n",
        "        export_revenue_percentage = random.randint(10, 70)\n",
        "\n",
        "        # Risk Metrics\n",
        "        credit_rating = random.choice(['AAA', 'AA+', 'AA', 'AA-', 'A+', 'A', 'A-', 'BBB+'])\n",
        "        risk_score = random.randint(65, 95)  # Higher is better\n",
        "\n",
        "        # Sales Pipeline Data\n",
        "        last_transaction_date = fake.date_between(\n",
        "            start_date='-6M',\n",
        "            end_date='today'\n",
        "        )\n",
        "        potential_annual_revenue = round(monthly_fx_volume * 12 * random.uniform(0.002, 0.004), 2)\n",
        "        lead_score = random.randint(1, 100)\n",
        "\n",
        "        # Contact Information\n",
        "        contact_name = fake.name()\n",
        "        contact_position = random.choice([\n",
        "            'Treasury Manager', 'CFO', 'Finance Director',\n",
        "            'Head of Finance', 'Financial Controller'\n",
        "        ])\n",
        "        contact_email = f\"{contact_name.lower().replace(' ', '.')}@{company_name.lower().replace(' ', '')}.co.uk\"\n",
        "        contact_phone = fake.phone_number()\n",
        "\n",
        "        # Create entry\n",
        "        entry = {\n",
        "            'Company Name': company_name,\n",
        "            'HQ Location': hq_location,\n",
        "            'Industry': industry,\n",
        "            'Year Established': year_established,\n",
        "            'Annual Revenue (£M)': annual_revenue,\n",
        "            'Market Cap (£M)': market_cap,\n",
        "            'Employees': employees,\n",
        "            'Monthly FX Volume (£M)': monthly_fx_volume,\n",
        "            'Primary Currency Pair': primary_currency_pair,\n",
        "            'Number of Currency Pairs': num_currency_pairs_traded,\n",
        "            'Primary Overseas Market': primary_overseas_market,\n",
        "            'Number of Overseas Subsidiaries': num_overseas_subsidiaries,\n",
        "            'Export Revenue %': export_revenue_percentage,\n",
        "            'Credit Rating': credit_rating,\n",
        "            'Risk Score': risk_score,\n",
        "            'Last Transaction Date': last_transaction_date,\n",
        "            'Potential Annual Revenue (£M)': potential_annual_revenue,\n",
        "            'Lead Score': lead_score,\n",
        "            'Contact Name': contact_name,\n",
        "            'Contact Position': contact_position,\n",
        "            'Contact Email': contact_email,\n",
        "            'Contact Phone': contact_phone\n",
        "        }\n",
        "\n",
        "        data.append(entry)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Generate the data\n",
        "fx_sales_data = generate_fx_sales_data()\n",
        "\n",
        "# Display the first few rows and basic statistics\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(fx_sales_data.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(fx_sales_data.info())\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "print(fx_sales_data.describe())\n",
        "\n",
        "# Save to CSV (optional)\n",
        "fx_sales_data.to_csv('fx_sales_data.csv', index=False)"
      ],
      "metadata": {
        "id": "pU44Ql74Z7H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "def prepare_data_for_classification(df):\n",
        "    \"\"\"Prepare data for classification\"\"\"\n",
        "    # Select features\n",
        "    features = [\n",
        "        'Annual Revenue (£M)',\n",
        "        'Monthly FX Volume (£M)',\n",
        "        'Export Revenue %',\n",
        "        'Lead Score',\n",
        "        'Number of Overseas Subsidiaries'\n",
        "    ]\n",
        "\n",
        "    # Create target variable (1 if FX volume is between 3-40M annually)\n",
        "    df['Target'] = ((df['Monthly FX Volume (£M)'] * 12 >= 3) &\n",
        "                   (df['Monthly FX Volume (£M)'] * 12 <= 40)).astype(int)\n",
        "\n",
        "    X = df[features]\n",
        "    y = df['Target']\n",
        "\n",
        "    return X, y, features\n",
        "\n",
        "def train_random_forest(X, y):\n",
        "    \"\"\"Train Random Forest model\"\"\"\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train model\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "    return rf, scaler, X_train_scaled, X_test_scaled, y_test, y_pred\n",
        "\n",
        "def calculate_lead_scores(model, X):\n",
        "    \"\"\"Calculate lead scores using model probabilities\"\"\"\n",
        "    return model.predict_proba(X)[:, 1]\n",
        "\n",
        "def create_interactive_visualizations(df, lead_scores):\n",
        "    # Add suitability scores to dataframe\n",
        "    df['Suitability_Score'] = lead_scores * 100\n",
        "\n",
        "    # Create main scatter plot\n",
        "    fig1 = px.scatter(\n",
        "        df,\n",
        "        x='Annual Revenue (£M)',\n",
        "        y='Monthly FX Volume (£M)',\n",
        "        color='Suitability_Score',\n",
        "        size='Lead Score',\n",
        "        hover_data=[\n",
        "            'Company Name',\n",
        "            'Industry',\n",
        "            'Suitability_Score',\n",
        "            'Number of Overseas Subsidiaries',\n",
        "            'Export Revenue %'\n",
        "        ],\n",
        "        color_continuous_scale='viridis',\n",
        "        title='Prospect Suitability Analysis'\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig1.update_layout(\n",
        "        height=800,\n",
        "        width=1200,\n",
        "        template='plotly_white',\n",
        "        hoverlabel=dict(\n",
        "            bgcolor=\"white\",\n",
        "            font_size=12,\n",
        "            font_family=\"Arial\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Add target zone indicators\n",
        "    fig1.add_hline(y=3/12, line_dash=\"dash\", line_color=\"red\",\n",
        "                   annotation_text=\"Min Target Volume\")\n",
        "    fig1.add_hline(y=40/12, line_dash=\"dash\", line_color=\"red\",\n",
        "                   annotation_text=\"Max Target Volume\")\n",
        "\n",
        "    fig1.show()\n",
        "\n",
        "    # Create industry analysis\n",
        "    fig2 = px.scatter(\n",
        "        df,\n",
        "        x='Export Revenue %',\n",
        "        y='Suitability_Score',\n",
        "        size='Monthly FX Volume (£M)',\n",
        "        color='Industry',\n",
        "        hover_data=[\n",
        "            'Company Name',\n",
        "            'Monthly FX Volume (£M)',\n",
        "            'Number of Overseas Subsidiaries',\n",
        "            'Lead Score'\n",
        "        ],\n",
        "        title='Industry-wise Prospect Analysis'\n",
        "    )\n",
        "\n",
        "    fig2.update_layout(\n",
        "        height=800,\n",
        "        width=1200,\n",
        "        template='plotly_white'\n",
        "    )\n",
        "\n",
        "    fig2.show()\n",
        "\n",
        "    # Create 3D analysis\n",
        "    fig3 = px.scatter_3d(\n",
        "        df,\n",
        "        x='Annual Revenue (£M)',\n",
        "        y='Export Revenue %',\n",
        "        z='Monthly FX Volume (£M)',\n",
        "        color='Industry',\n",
        "        size='Suitability_Score',\n",
        "        hover_data=[\n",
        "            'Company Name',\n",
        "            'Suitability_Score',\n",
        "            'Lead Score'\n",
        "        ],\n",
        "        title='3D Prospect Analysis'\n",
        "    )\n",
        "\n",
        "    fig3.update_layout(\n",
        "        height=800,\n",
        "        width=1200,\n",
        "        scene=dict(\n",
        "            xaxis_title='Annual Revenue (£M)',\n",
        "            yaxis_title='Export Revenue %',\n",
        "            zaxis_title='Monthly FX Volume (£M)'\n",
        "        )\n",
        "    )\n",
        "\n",
        "    fig3.show()\n",
        "\n",
        "    # Create summary statistics\n",
        "    summary_stats = df.groupby('Industry').agg({\n",
        "        'Suitability_Score': ['mean', 'count'],\n",
        "        'Monthly FX Volume (£M)': 'mean',\n",
        "        'Export Revenue %': 'mean'\n",
        "    }).round(2)\n",
        "\n",
        "    print(\"\\nIndustry Summary Statistics:\")\n",
        "    print(summary_stats)\n",
        "\n",
        "    # Save plots (optional)\n",
        "    fig1.write_html(\"suitability_analysis.html\")\n",
        "    fig2.write_html(\"industry_analysis.html\")\n",
        "    fig3.write_html(\"3d_analysis.html\")\n",
        "\n",
        "def generate_fx_sales_data(n_samples=1000):\n",
        "    \"\"\"Generate synthetic FX sales data\"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    data = []\n",
        "    industries = ['Food & Beverage', 'Travel', 'Tech', 'Engineering']\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        record = {\n",
        "            'Company Name': f'Company_{i}',\n",
        "            'Industry': np.random.choice(industries),\n",
        "            'Annual Revenue (£M)': np.random.uniform(10, 500),\n",
        "            'Monthly FX Volume (£M)': np.random.uniform(0.1, 5),\n",
        "            'Export Revenue %': np.random.uniform(0, 100),\n",
        "            'Lead Score': np.random.uniform(0, 100),\n",
        "            'Number of Overseas Subsidiaries': np.random.randint(0, 20)\n",
        "        }\n",
        "        data.append(record)\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def main():\n",
        "    # Generate sample data\n",
        "    fx_sales_data = generate_fx_sales_data()\n",
        "\n",
        "    # Prepare data\n",
        "    X, y, features = prepare_data_for_classification(fx_sales_data)\n",
        "\n",
        "    # Train model\n",
        "    rf, scaler, X_train_scaled, X_test_scaled, y_test, y_pred = train_random_forest(X, y)\n",
        "\n",
        "    # Calculate lead scores\n",
        "    lead_scores = calculate_lead_scores(rf, scaler.transform(X))\n",
        "\n",
        "    # Create visualizations\n",
        "    create_interactive_visualizations(fx_sales_data, lead_scores)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Display top prospects\n",
        "    print(\"\\nTop 10 Most Suitable Prospects:\")\n",
        "    fx_sales_data['Suitability_Score'] = lead_scores * 100\n",
        "    top_prospects = fx_sales_data.sort_values('Suitability_Score', ascending=False).head(10)\n",
        "    print(top_prospects[['Company Name', 'Industry', 'Monthly FX Volume (£M)', 'Suitability_Score']])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "sFZVKwT9gggc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fx_customer_data(n_samples=1000):\n",
        "    \"\"\"Generate synthetic FX customer data\"\"\"\n",
        "    try:\n",
        "        np.random.seed(42)\n",
        "\n",
        "        # Define industry distribution\n",
        "        industries = ['Food & Beverage', 'Travel', 'Tech', 'Engineering']\n",
        "        industry_weights = [0.3, 0.2, 0.3, 0.2]  # Weights for each industry\n",
        "\n",
        "        data = []\n",
        "        for i in range(n_samples):\n",
        "            # Generate base metrics\n",
        "            industry = np.random.choice(industries, p=industry_weights)\n",
        "\n",
        "            # Adjust metrics based on industry\n",
        "            if industry == 'Tech':\n",
        "                revenue_range = (50, 500)\n",
        "                volume_range = (0.5, 8)\n",
        "                export_range = (30, 90)\n",
        "            elif industry == 'Food & Beverage':\n",
        "                revenue_range = (20, 300)\n",
        "                volume_range = (0.2, 5)\n",
        "                export_range = (10, 60)\n",
        "            elif industry == 'Travel':\n",
        "                revenue_range = (10, 200)\n",
        "                volume_range = (0.1, 3)\n",
        "                export_range = (20, 80)\n",
        "            else:  # Engineering\n",
        "                revenue_range = (30, 400)\n",
        "                volume_range = (0.3, 6)\n",
        "                export_range = (40, 90)\n",
        "\n",
        "            record = {\n",
        "                'Company Name': f'Company_{i:04d}',\n",
        "                'Industry': industry,\n",
        "                'Annual Revenue (£M)': np.random.uniform(*revenue_range),\n",
        "                'Monthly FX Volume (£M)': np.random.uniform(*volume_range),\n",
        "                'Export Revenue %': np.random.uniform(*export_range),\n",
        "                'Lead Score': np.random.uniform(0, 100),\n",
        "                'Number of Overseas Subsidiaries': np.random.randint(0, 20),\n",
        "                'Years in Business': np.random.randint(1, 50),\n",
        "                'Number of Employees': np.random.randint(50, 5000),\n",
        "                'Credit Rating': np.random.choice(['AAA', 'AA', 'A', 'BBB+', 'BBB']),\n",
        "                'Geographic Presence': np.random.randint(1, 10),\n",
        "                'Product Complexity': np.random.choice(['Low', 'Medium', 'High']),\n",
        "                'Digital Maturity': np.random.choice(['Low', 'Medium', 'High']),\n",
        "                'Customer Base': np.random.randint(10, 1000)\n",
        "            }\n",
        "\n",
        "            data.append(record)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Add some derived metrics\n",
        "        df['Revenue per Employee'] = df['Annual Revenue (£M)'] * 1e6 / df['Number of Employees']\n",
        "        df['FX Volume per Revenue'] = df['Monthly FX Volume (£M)'] / df['Annual Revenue (£M)']\n",
        "        df['International Exposure Score'] = (\n",
        "            df['Export Revenue %'] * 0.4 +\n",
        "            df['Number of Overseas Subsidiaries'] * 5 * 0.3 +\n",
        "            df['Geographic Presence'] * 10 * 0.3\n",
        "        )\n",
        "\n",
        "        print(f\"Generated {len(df)} records with {len(df.columns)} features\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in data generation: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Generate sample data\n",
        "        print(\"Generating sample data...\")\n",
        "        fx_sales_data = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        if fx_sales_data is None or fx_sales_data.empty:\n",
        "            raise ValueError(\"Failed to generate sample data\")\n",
        "\n",
        "        print(\"\\nData Sample:\")\n",
        "        print(fx_sales_data.head())\n",
        "        print(\"\\nData Summary:\")\n",
        "        print(fx_sales_data.describe())\n",
        "\n",
        "        # Prepare data\n",
        "        print(\"\\nPreparing data for classification...\")\n",
        "        X, y, features = prepare_data_for_classification(fx_sales_data)\n",
        "\n",
        "        if X is None or y is None:\n",
        "            raise ValueError(\"Failed to prepare data for classification\")\n",
        "\n",
        "        # Train model\n",
        "        print(\"Training random forest model...\")\n",
        "        rf, scaler, X_train_scaled, X_test_scaled, y_test, y_pred = train_random_forest(X, y)\n",
        "\n",
        "        if rf is None:\n",
        "            raise ValueError(\"Failed to train random forest model\")\n",
        "\n",
        "        # Calculate lead scores\n",
        "        print(\"Calculating lead scores...\")\n",
        "        lead_scores = calculate_lead_scores(rf, scaler.transform(X))\n",
        "\n",
        "        if lead_scores is None:\n",
        "            raise ValueError(\"Failed to calculate lead scores\")\n",
        "\n",
        "        # Store lead scores\n",
        "        fx_sales_data['Suitability_Score'] = lead_scores * 100\n",
        "\n",
        "        # Perform advanced analysis\n",
        "        print(\"Performing advanced analysis...\")\n",
        "        feature_importance = analyze_feature_importance(rf, fx_sales_data)\n",
        "        segments = perform_customer_segmentation(fx_sales_data)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        if feature_importance is not None:\n",
        "            print(\"\\nTop 5 Important Features:\")\n",
        "            print(feature_importance['importance'].head())\n",
        "\n",
        "        if segments is not None:\n",
        "            print(\"\\nSegment Profiles:\")\n",
        "            print(segments['profiles'])\n",
        "\n",
        "        # Display top prospects\n",
        "        print(\"\\nTop 10 Most Suitable Prospects:\")\n",
        "        top_prospects = fx_sales_data.sort_values('Suitability_Score', ascending=False).head(10)\n",
        "        print(top_prospects[['Company Name', 'Industry', 'Monthly FX Volume (£M)', 'Suitability_Score']])\n",
        "\n",
        "        return fx_sales_data, rf, feature_importance, segments\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        return None, None, None, None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        data, model, importance, segments = main()\n",
        "\n",
        "        if all(v is not None for v in [data, model, importance, segments]):\n",
        "            print(\"\\nAnalysis completed successfully!\")\n",
        "        else:\n",
        "            print(\"\\nAnalysis completed with some failures.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Script failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        sys.exit(1)"
      ],
      "metadata": {
        "id": "hwLDWoTEkKq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fx_customer_data(n_samples=1000):\n",
        "    \"\"\"Generate synthetic FX customer data\"\"\"\n",
        "    try:\n",
        "        np.random.seed(42)\n",
        "        fake = Faker()\n",
        "\n",
        "        data = []\n",
        "        for i in range(n_samples):\n",
        "            record = {\n",
        "                'customer_id': f'CUST_{i:04d}',\n",
        "                'date': fake.date_between(start_date='-2y', end_date='today'),\n",
        "                'industry': np.random.choice(['Finance', 'Tech', 'Food & Beverage', 'Retail', 'Travel']),\n",
        "                'company_size': np.random.choice(['Small', 'Medium', 'Large', 'Enterprise']),\n",
        "                'monthly_volume': np.random.uniform(0.1, 100),\n",
        "                'spot_ratio': np.random.uniform(0, 1),\n",
        "                'forward_ratio': np.random.uniform(0, 1),\n",
        "                'login_frequency': np.random.randint(1, 100),\n",
        "                'quote_requests': np.random.randint(0, 50),\n",
        "                'support_tickets': np.random.randint(0, 20),\n",
        "                'meeting_count': np.random.randint(0, 10),\n",
        "                'platform_usage_hours': np.random.uniform(1, 200),\n",
        "                'credit_score': np.random.uniform(300, 850),\n",
        "                'risk_score': np.random.uniform(1, 100),\n",
        "                'engagement_score': np.random.uniform(0, 100),\n",
        "                'volume_change': np.random.uniform(-0.5, 0.5),\n",
        "                'engagement_change': np.random.uniform(-0.3, 0.3),\n",
        "                'annual_revenue': np.random.uniform(1e6, 1e9),\n",
        "                'employees': np.random.randint(10, 10000),\n",
        "                'response_time_hours': np.random.uniform(0, 72),\n",
        "                'churned': np.random.choice([0, 1], p=[0.8, 0.2])  # Using numpy's random choice\n",
        "            }\n",
        "\n",
        "            # Add industry-specific features\n",
        "            if record['industry'] == 'Food & Beverage':\n",
        "                record.update({\n",
        "                    'seasonal_impact': np.random.uniform(0, 1),\n",
        "                    'commodity_exposure': np.random.uniform(0.3, 0.8),\n",
        "                    'supplier_countries': np.random.randint(2, 10)\n",
        "                })\n",
        "            elif record['industry'] == 'Tech':\n",
        "                record.update({\n",
        "                    'growth_rate': np.random.uniform(0.1, 0.4),\n",
        "                    'dev_center_countries': np.random.randint(1, 5),\n",
        "                    'subscription_revenue_ratio': np.random.uniform(0.4, 0.9)\n",
        "                })\n",
        "            elif record['industry'] == 'Retail':\n",
        "                record.update({\n",
        "                    'peak_season_volume': np.random.uniform(1.2, 2.0),\n",
        "                    'currency_pairs_count': np.random.randint(3, 10),\n",
        "                    'booking_volatility': np.random.uniform(0.1, 0.4)\n",
        "                })\n",
        "            else:  # Travel or Finance\n",
        "                record.update({\n",
        "                    'project_count': np.random.randint(1, 15),\n",
        "                    'equipment_import_ratio': np.random.uniform(0.2, 0.7),\n",
        "                    'contract_duration_months': np.random.randint(6, 36)\n",
        "                })\n",
        "\n",
        "            data.append(record)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        print(f\"Generated {len(df)} records with {len(df.columns)} features\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in data generation: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "RhI7XazYlUza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import logging\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "# Set up logging\n",
        "log_filename = f'churn_model_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(log_filename),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def generate_fx_customer_data(n_samples=1000):\n",
        "    \"\"\"Generate synthetic FX customer data with churn indicators\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Starting data generation for {n_samples} samples\")\n",
        "        np.random.seed(42)\n",
        "        start_date = datetime(2020, 1, 1)\n",
        "\n",
        "        # Basic company profiles\n",
        "        industries = ['Food & Beverage', 'Travel', 'Tech', 'Engineering']\n",
        "        company_sizes = ['Small', 'Medium', 'Large', 'Enterprise']\n",
        "\n",
        "        data = []\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # Generate base customer data\n",
        "            customer_data = {\n",
        "                'customer_id': f'CUST_{i:04d}',\n",
        "                'industry': np.random.choice(industries),\n",
        "                'company_size': np.random.choice(company_sizes),\n",
        "                'date': start_date + timedelta(days=np.random.randint(0, 365*2)),\n",
        "                'annual_revenue': np.random.uniform(1e6, 1e9),\n",
        "                'employees': np.random.randint(50, 10000)\n",
        "            }\n",
        "\n",
        "            # Add transaction metrics\n",
        "            customer_data.update({\n",
        "                'monthly_volume': np.random.uniform(1e5, 1e7),\n",
        "                'spot_ratio': np.random.uniform(0.3, 0.7),\n",
        "                'forward_ratio': np.random.uniform(0.3, 0.7),\n",
        "                'avg_transaction_size': np.random.uniform(1e4, 1e6),\n",
        "                'transaction_frequency': np.random.randint(5, 100)\n",
        "            })\n",
        "\n",
        "            # Add engagement metrics\n",
        "            customer_data.update({\n",
        "                'login_frequency': np.random.randint(1, 30),\n",
        "                'support_tickets': np.random.randint(0, 10),\n",
        "                'meeting_count': np.random.randint(0, 5),\n",
        "                'platform_usage_hours': np.random.uniform(1, 100),\n",
        "                'response_time_hours': np.random.uniform(1, 48)\n",
        "            })\n",
        "\n",
        "            # Add risk metrics\n",
        "            customer_data.update({\n",
        "                'credit_score': np.random.uniform(300, 850),\n",
        "                'risk_score': np.random.uniform(1, 100),\n",
        "                'payment_delays': np.random.randint(0, 5),\n",
        "                'failed_transactions': np.random.randint(0, 3)\n",
        "            })\n",
        "\n",
        "            # Calculate churn probability and status\n",
        "            churn_factors = [\n",
        "                customer_data['payment_delays'] > 2,\n",
        "                customer_data['failed_transactions'] > 1,\n",
        "                customer_data['login_frequency'] < 5,\n",
        "                customer_data['support_tickets'] > 5\n",
        "            ]\n",
        "\n",
        "            churn_probability = sum(churn_factors) / len(churn_factors)\n",
        "            customer_data['churned'] = 1 if np.random.random() < churn_probability else 0\n",
        "\n",
        "            data.append(customer_data)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Validate generated data\n",
        "        if df.empty:\n",
        "            raise ValueError(\"Generated DataFrame is empty\")\n",
        "\n",
        "        logger.info(f\"Successfully generated {len(df)} records\")\n",
        "        logger.info(f\"Churn rate: {df['churned'].mean():.2%}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in data generation: {str(e)}\")\n",
        "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "        raise\n",
        "\n",
        "def validate_dataset(df):\n",
        "    \"\"\"Validate the generated dataset\"\"\"\n",
        "    try:\n",
        "        # Check for minimum size\n",
        "        if len(df) < 100:\n",
        "            raise ValueError(\"Dataset too small: minimum 100 records required\")\n",
        "\n",
        "        # Check for required columns\n",
        "        required_columns = [\n",
        "            'customer_id', 'industry', 'company_size', 'monthly_volume',\n",
        "            'login_frequency', 'churned'\n",
        "        ]\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "        if missing_columns:\n",
        "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
        "\n",
        "        # Check for data types\n",
        "        if not pd.api.types.is_numeric_dtype(df['monthly_volume']):\n",
        "            raise ValueError(\"monthly_volume must be numeric\")\n",
        "\n",
        "        # Check for missing values\n",
        "        missing_values = df.isnull().sum()\n",
        "        if missing_values.any():\n",
        "            logger.warning(f\"Missing values found:\\n{missing_values[missing_values > 0]}\")\n",
        "\n",
        "        # Check class balance\n",
        "        churn_rate = df['churned'].mean()\n",
        "        if churn_rate < 0.05 or churn_rate > 0.95:\n",
        "            logger.warning(f\"Severe class imbalance detected: {churn_rate:.2%} churn rate\")\n",
        "\n",
        "        logger.info(\"Dataset validation completed successfully\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Dataset validation failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Generate data\n",
        "        logger.info(\"Starting data generation process...\")\n",
        "        df = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        # Validate dataset\n",
        "        if not validate_dataset(df):\n",
        "            raise ValueError(\"Dataset validation failed\")\n",
        "\n",
        "        # Continue with the rest of your processing...\n",
        "        logger.info(\"Data generation and validation completed successfully\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {str(e)}\")\n",
        "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        result = main()\n",
        "        if result is None:\n",
        "            logger.error(\"Script failed to complete successfully\")\n",
        "            sys.exit(1)\n",
        "        else:\n",
        "            logger.info(f\"Script completed successfully. Generated {len(result)} records\")\n",
        "            # Save the data (optional)\n",
        "            result.to_csv('fx_customer_data.csv', index=False)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Unexpected error in script execution: {str(e)}\")\n",
        "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
        "        sys.exit(1)"
      ],
      "metadata": {
        "id": "Tet8hMviVdiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelPipeline:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = PCA(n_components=0.95)  # Explain 95% of variance\n",
        "        self.feature_importance = None\n",
        "        self.best_model = None\n",
        "        self.feature_columns = None  # Add this line\n",
        "        logger.info(\"ChurnModelPipeline initialized\")\n",
        "\n",
        "    def engineer_features(self):\n",
        "        \"\"\"Create advanced features for the model\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting feature engineering...\")\n",
        "\n",
        "            # Create time-based features\n",
        "            self.df['days_since_first_transaction'] = (\n",
        "                self.df.groupby('customer_id')['date']\n",
        "                .transform('max') - self.df.groupby('customer_id')['date']\n",
        "                .transform('min')\n",
        "            ).dt.days\n",
        "\n",
        "            # Create ratio features\n",
        "            self.df['volume_per_login'] = self.df['monthly_volume'] / self.df['login_frequency'].clip(lower=1)\n",
        "            self.df['tickets_per_volume'] = self.df['support_tickets'] / self.df['monthly_volume'].clip(lower=1)\n",
        "            self.df['revenue_per_employee'] = self.df['annual_revenue'] / self.df['employees'].clip(lower=1)\n",
        "\n",
        "            # Create interaction features\n",
        "            self.df['risk_volume_interaction'] = self.df['risk_score'] * self.df['monthly_volume']\n",
        "            self.df['engagement_score'] = (\n",
        "                self.df['login_frequency'] * 0.3 +\n",
        "                self.df['platform_usage_hours'] * 0.3 +\n",
        "                (1 - self.df['response_time_hours']/48) * 0.2 +\n",
        "                (1 - self.df['support_tickets']/10) * 0.2\n",
        "            ) * 100\n",
        "\n",
        "            # Create categorical encodings\n",
        "            categorical_columns = ['industry', 'company_size']\n",
        "            for col in categorical_columns:\n",
        "                dummies = pd.get_dummies(self.df[col], prefix=col)\n",
        "                self.df = pd.concat([self.df, dummies], axis=1)\n",
        "\n",
        "            logger.info(\"Feature engineering completed successfully\")\n",
        "            return self.df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature engineering: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Prepare features for modeling\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Preparing features for modeling...\")\n",
        "\n",
        "            # Select features for modeling\n",
        "            self.feature_columns = [  # Store as instance variable\n",
        "                'monthly_volume', 'spot_ratio', 'forward_ratio',\n",
        "                'login_frequency', 'support_tickets', 'platform_usage_hours',\n",
        "                'credit_score', 'risk_score', 'volume_per_login',\n",
        "                'tickets_per_volume', 'revenue_per_employee',\n",
        "                'risk_volume_interaction', 'engagement_score',\n",
        "                'days_since_first_transaction'\n",
        "            ]\n",
        "\n",
        "            # Add dummy columns\n",
        "            dummy_columns = [col for col in self.df.columns if 'industry_' in col or 'company_size_' in col]\n",
        "            self.feature_columns.extend(dummy_columns)\n",
        "\n",
        "            # Prepare X and y\n",
        "            X = self.df[self.feature_columns]\n",
        "            y = self.df['churned']\n",
        "\n",
        "            # Scale features\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "            logger.info(f\"Prepared {len(self.feature_columns)} features for modeling\")\n",
        "            return X_scaled, y, self.feature_columns\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature preparation: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    # [Rest of the methods remain the same until visualize_results]\n",
        "\n",
        "    def visualize_results(self, results, X_test, y_test):\n",
        "        \"\"\"Create visualizations of model performance\"\"\"\n",
        "        try:\n",
        "            if self.feature_columns is None:\n",
        "                raise ValueError(\"Feature columns not set. Run prepare_features first.\")\n",
        "\n",
        "            # Create figure with subplots\n",
        "            plt.figure(figsize=(20, 10))\n",
        "\n",
        "            # 1. ROC Curves\n",
        "            plt.subplot(2, 2, 1)\n",
        "            for name, result in results.items():\n",
        "                fpr, tpr, _ = roc_curve(y_test, result['predictions'])\n",
        "                plt.plot(fpr, tpr, label=f\"{name} (AUC = {result['auc_roc']:.3f})\")\n",
        "\n",
        "            plt.plot([0, 1], [0, 1], 'k--')\n",
        "            plt.xlabel('False Positive Rate')\n",
        "            plt.ylabel('True Positive Rate')\n",
        "            plt.title('ROC Curves')\n",
        "            plt.legend()\n",
        "\n",
        "            # 2. Precision-Recall Curves\n",
        "            plt.subplot(2, 2, 2)\n",
        "            for name, result in results.items():\n",
        "                precision, recall, _ = precision_recall_curve(y_test, result['predictions'])\n",
        "                plt.plot(recall, precision, label=f\"{name} (AP = {result['avg_precision']:.3f})\")\n",
        "\n",
        "            plt.xlabel('Recall')\n",
        "            plt.ylabel('Precision')\n",
        "            plt.title('Precision-Recall Curves')\n",
        "            plt.legend()\n",
        "\n",
        "            # 3. Feature Importance (for best model)\n",
        "            if hasattr(self.best_model, 'feature_importances_'):\n",
        "                plt.subplot(2, 2, 3)\n",
        "                importances = pd.Series(\n",
        "                    self.best_model.feature_importances_,\n",
        "                    index=self.feature_columns\n",
        "                ).sort_values(ascending=False)[:10]\n",
        "\n",
        "                sns.barplot(x=importances.values, y=importances.index)\n",
        "                plt.title('Top 10 Feature Importance')\n",
        "\n",
        "            # 4. Confusion Matrix\n",
        "            plt.subplot(2, 2, 4)\n",
        "            cm = confusion_matrix(y_test, self.best_model.predict(X_test))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "            plt.title('Confusion Matrix')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in visualization: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "y8Iv8BuUVu9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelPipeline:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = PCA(n_components=0.95)\n",
        "        self.feature_importance = None\n",
        "        self.best_model = None\n",
        "        self.feature_columns = []  # Initialize as empty list\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "        logger.info(\"ChurnModelPipeline initialized\")\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Prepare features for modeling\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Preparing features for modeling...\")\n",
        "\n",
        "            # Select features for modeling\n",
        "            self.feature_columns = [\n",
        "                'monthly_volume', 'spot_ratio', 'forward_ratio',\n",
        "                'login_frequency', 'support_tickets', 'platform_usage_hours',\n",
        "                'credit_score', 'risk_score', 'volume_per_login',\n",
        "                'tickets_per_volume', 'revenue_per_employee',\n",
        "                'risk_volume_interaction', 'engagement_score',\n",
        "                'days_since_first_transaction'\n",
        "            ]\n",
        "\n",
        "            # Verify all columns exist in dataframe\n",
        "            missing_columns = [col for col in self.feature_columns if col not in self.df.columns]\n",
        "            if missing_columns:\n",
        "                raise ValueError(f\"Missing columns in dataframe: {missing_columns}\")\n",
        "\n",
        "            # Add dummy columns\n",
        "            dummy_columns = [col for col in self.df.columns if 'industry_' in col or 'company_size_' in col]\n",
        "            self.feature_columns.extend(dummy_columns)\n",
        "\n",
        "            # Prepare X and y\n",
        "            X = self.df[self.feature_columns]\n",
        "            y = self.df['churned']\n",
        "\n",
        "            # Check for missing values\n",
        "            if X.isnull().any().any():\n",
        "                logger.warning(\"Missing values found in features. Filling with zeros.\")\n",
        "                X = X.fillna(0)\n",
        "\n",
        "            # Scale features\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "            logger.info(f\"Prepared {len(self.feature_columns)} features for modeling\")\n",
        "\n",
        "            # Verify shapes\n",
        "            logger.info(f\"X shape: {X_scaled.shape}, y shape: {y.shape}\")\n",
        "\n",
        "            return X_scaled, y, self.feature_columns\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature preparation: {str(e)}\")\n",
        "            logger.error(f\"Available columns: {list(self.df.columns)}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "id": "aYBWKVBObrQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelPipeline:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = PCA(n_components=0.95)\n",
        "        self.feature_importance = None\n",
        "        self.best_model = None\n",
        "        self.feature_columns = []\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "        logger.info(\"ChurnModelPipeline initialized\")\n",
        "\n",
        "    def engineer_features(self):\n",
        "        \"\"\"Create advanced features for the model\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting feature engineering...\")\n",
        "\n",
        "            # Create time-based features\n",
        "            self.df['days_since_first_transaction'] = (\n",
        "                self.df.groupby('customer_id')['date']\n",
        "                .transform('max') - self.df.groupby('customer_id')['date']\n",
        "                .transform('min')\n",
        "            ).dt.days\n",
        "\n",
        "            # Create ratio features\n",
        "            self.df['volume_per_login'] = self.df['monthly_volume'] / self.df['login_frequency'].clip(lower=1)\n",
        "            self.df['tickets_per_volume'] = self.df['support_tickets'] / self.df['monthly_volume'].clip(lower=1)\n",
        "            self.df['revenue_per_employee'] = self.df['annual_revenue'] / self.df['employees'].clip(lower=1)\n",
        "\n",
        "            # Create interaction features\n",
        "            self.df['risk_volume_interaction'] = self.df['risk_score'] * self.df['monthly_volume']\n",
        "            self.df['engagement_score'] = (\n",
        "                self.df['login_frequency'] * 0.3 +\n",
        "                self.df['platform_usage_hours'] * 0.3 +\n",
        "                (1 - self.df['response_time_hours']/48) * 0.2 +\n",
        "                (1 - self.df['support_tickets']/10) * 0.2\n",
        "            ) * 100\n",
        "\n",
        "            # Create categorical encodings\n",
        "            categorical_columns = ['industry', 'company_size']\n",
        "            for col in categorical_columns:\n",
        "                dummies = pd.get_dummies(self.df[col], prefix=col)\n",
        "                self.df = pd.concat([self.df, dummies], axis=1)\n",
        "\n",
        "            logger.info(\"Feature engineering completed successfully\")\n",
        "            return self.df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature engineering: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Prepare features for modeling\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Preparing features for modeling...\")\n",
        "\n",
        "            # Select features for modeling\n",
        "            self.feature_columns = [\n",
        "                'monthly_volume', 'spot_ratio', 'forward_ratio',\n",
        "                'login_frequency', 'support_tickets', 'platform_usage_hours',\n",
        "                'credit_score', 'risk_score', 'volume_per_login',\n",
        "                'tickets_per_volume', 'revenue_per_employee',\n",
        "                'risk_volume_interaction', 'engagement_score',\n",
        "                'days_since_first_transaction'\n",
        "            ]\n",
        "\n",
        "            # Verify all columns exist in dataframe\n",
        "            missing_columns = [col for col in self.feature_columns if col not in self.df.columns]\n",
        "            if missing_columns:\n",
        "                raise ValueError(f\"Missing columns in dataframe: {missing_columns}\")\n",
        "\n",
        "            # Add dummy columns\n",
        "            dummy_columns = [col for col in self.df.columns if 'industry_' in col or 'company_size_' in col]\n",
        "            self.feature_columns.extend(dummy_columns)\n",
        "\n",
        "            # Prepare X and y\n",
        "            X = self.df[self.feature_columns]\n",
        "            y = self.df['churned']\n",
        "\n",
        "            # Check for missing values\n",
        "            if X.isnull().any().any():\n",
        "                logger.warning(\"Missing values found in features. Filling with zeros.\")\n",
        "                X = X.fillna(0)\n",
        "\n",
        "            # Scale features\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "            logger.info(f\"Prepared {len(self.feature_columns)} features for modeling\")\n",
        "            return X_scaled, y, self.feature_columns\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature preparation: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def apply_pca(self, X):\n",
        "        \"\"\"Apply PCA transformation\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Applying PCA...\")\n",
        "\n",
        "            # Verify input\n",
        "            if X is None:\n",
        "                raise ValueError(\"Input matrix X is None\")\n",
        "\n",
        "            if len(X.shape) != 2:\n",
        "                raise ValueError(f\"Expected 2D array, got {len(X.shape)}D\")\n",
        "\n",
        "            # Apply PCA\n",
        "            X_pca = self.pca.fit_transform(X)\n",
        "\n",
        "            # Calculate explained variance\n",
        "            explained_variance = np.cumsum(self.pca.explained_variance_ratio_)\n",
        "\n",
        "            # Log PCA results\n",
        "            logger.info(f\"Number of components selected: {self.pca.n_components_}\")\n",
        "            logger.info(f\"Total variance explained: {explained_variance[-1]:.3f}\")\n",
        "\n",
        "            # Store PCA attributes\n",
        "            self.n_components_ = self.pca.n_components_\n",
        "            self.explained_variance_ratio_ = self.pca.explained_variance_ratio_\n",
        "            self.components_ = self.pca.components_\n",
        "\n",
        "            # Create component names\n",
        "            self.pca_features = [f'PC{i+1}' for i in range(self.n_components_)]\n",
        "\n",
        "            # Create loadings dataframe\n",
        "            self.pca_loadings = pd.DataFrame(\n",
        "                self.components_,\n",
        "                columns=self.feature_columns,\n",
        "                index=self.pca_features\n",
        "            )\n",
        "\n",
        "            return X_pca, explained_variance\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in PCA application: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_models(self, X, y):\n",
        "        \"\"\"Train and evaluate multiple models\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Training models...\")\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "            # Store test data\n",
        "            self.X_test = X_test\n",
        "            self.y_test = y_test\n",
        "\n",
        "            # Initialize models\n",
        "            models = {\n",
        "                'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "                'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "            }\n",
        "\n",
        "            # Train and evaluate models\n",
        "            results = {}\n",
        "            for name, model in models.items():\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "                results[name] = {\n",
        "                    'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
        "                    'avg_precision': average_precision_score(y_test, y_pred_proba),\n",
        "                    'model': model,\n",
        "                    'predictions': y_pred_proba\n",
        "                }\n",
        "\n",
        "                logger.info(f\"{name} - AUC ROC: {results[name]['auc_roc']:.3f}\")\n",
        "\n",
        "            # Select best model\n",
        "            best_model_name = max(results.items(), key=lambda x: x[1]['auc_roc'])[0]\n",
        "            self.best_model = results[best_model_name]['model']\n",
        "\n",
        "            logger.info(f\"Best model: {best_model_name}\")\n",
        "            return results, X_test, y_test\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in model training: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "VtGP8s0rcyvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fx_customer_data(n_samples=1000):\n",
        "    \"\"\"Generate synthetic FX customer data\"\"\"\n",
        "    try:\n",
        "        fake = Faker()\n",
        "        np.random.seed(42)  # For reproducibility\n",
        "\n",
        "        data = []\n",
        "        for i in range(n_samples):\n",
        "            # Use numpy's random choice instead of random.choice\n",
        "            record = {\n",
        "                'customer_id': f'CUST_{i:04d}',\n",
        "                'date': fake.date_between(start_date='-2y', end_date='today'),\n",
        "                'industry': np.random.choice(['Finance', 'Tech', 'Food & Beverage', 'Retail', 'Travel']),\n",
        "                'company_size': np.random.choice(['Small', 'Medium', 'Large', 'Enterprise']),\n",
        "                'monthly_volume': np.random.uniform(0.1, 100),\n",
        "                'spot_ratio': np.random.uniform(0, 1),\n",
        "                'forward_ratio': np.random.uniform(0, 1),\n",
        "                'login_frequency': np.random.randint(1, 100),\n",
        "                'support_tickets': np.random.randint(0, 20),\n",
        "                'platform_usage_hours': np.random.uniform(1, 200),\n",
        "                'credit_score': np.random.uniform(300, 850),\n",
        "                'risk_score': np.random.uniform(1, 100),\n",
        "                'annual_revenue': np.random.uniform(1e6, 1e9),\n",
        "                'employees': np.random.randint(10, 10000),\n",
        "                'response_time_hours': np.random.uniform(0, 72),\n",
        "                # Use numpy's random choice for churned with probability\n",
        "                'churned': np.random.choice([0, 1], p=[0.8, 0.2])\n",
        "            }\n",
        "            data.append(record)\n",
        "\n",
        "        df = pd.DataFrame(data)\n",
        "        logger.info(f\"Generated {len(df)} records with {len(df.columns)} features\")\n",
        "\n",
        "        # Validate generated data\n",
        "        if df.isnull().any().any():\n",
        "            logger.warning(\"Generated data contains null values\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in data generation: {str(e)}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "        return None"
      ],
      "metadata": {
        "id": "L_qfFlbmkRD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_interactive_dashboard(pipeline, results):\n",
        "    \"\"\"Create comprehensive interactive dashboard\"\"\"\n",
        "    # Add visualization code from earlier"
      ],
      "metadata": {
        "id": "a0Ob8ksNm1rC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_model_decisions(pipeline):\n",
        "    \"\"\"Analyze and explain model decisions\"\"\"\n",
        "    # SHAP values\n",
        "    # Feature interactions\n",
        "    # Decision paths"
      ],
      "metadata": {
        "id": "zF7kBtGcnnug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_customer_segmentation(df):\n",
        "    \"\"\"Segment customers based on behavior\"\"\"\n",
        "    # Clustering\n",
        "    # Segment profiling\n",
        "    # Segment-specific insights"
      ],
      "metadata": {
        "id": "JM6aob0rnqhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_risk_profiles(df):\n",
        "    \"\"\"Analyze customer risk profiles\"\"\"\n",
        "    # Risk scoring\n",
        "    # Risk factors\n",
        "    # Risk trends"
      ],
      "metadata": {
        "id": "BnsCrI_lnsA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommendations(pipeline):\n",
        "    \"\"\"Generate customer-specific recommendations\"\"\"\n",
        "    # Product recommendations\n",
        "    # Risk mitigation suggestions\n",
        "    # Engagement strategies"
      ],
      "metadata": {
        "id": "ScyNuagqnt0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import dash\n",
        "from dash import dcc, html\n",
        "from dash.dependencies import Input, Output, State\n",
        "import dash_bootstrap_components as dbc\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class ComprehensiveDashboard:\n",
        "    def __init__(self, pipeline, results, data):\n",
        "        self.pipeline = pipeline\n",
        "        self.results = results\n",
        "        self.data = data\n",
        "        self.app = dash.Dash(__name__, external_stylesheets=[dbc.themes.FLATLY])\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Header\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    html.H1(\"FX Sales Analytics Dashboard\",\n",
        "                           className=\"text-center mb-4\"),\n",
        "                    html.Hr()\n",
        "                ])\n",
        "            ]),\n",
        "\n",
        "            # Control Panel\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Control Panel\"),\n",
        "                        dbc.CardBody([\n",
        "                            dbc.Row([\n",
        "                                dbc.Col([\n",
        "                                    html.Label(\"Select Industry\"),\n",
        "                                    dcc.Dropdown(\n",
        "                                        id='industry-filter',\n",
        "                                        options=[{'label': x, 'value': x}\n",
        "                                                for x in self.data['Industry'].unique()],\n",
        "                                        value='All',\n",
        "                                        clearable=False\n",
        "                                    )\n",
        "                                ], width=4),\n",
        "                                dbc.Col([\n",
        "                                    html.Label(\"Select Analysis Type\"),\n",
        "                                    dcc.Dropdown(\n",
        "                                        id='analysis-type',\n",
        "                                        options=[\n",
        "                                            {'label': 'Customer Overview', 'value': 'overview'},\n",
        "                                            {'label': 'Risk Analysis', 'value': 'risk'},\n",
        "                                            {'label': 'Performance Metrics', 'value': 'performance'},\n",
        "                                            {'label': 'Segmentation', 'value': 'segmentation'}\n",
        "                                        ],\n",
        "                                        value='overview',\n",
        "                                        clearable=False\n",
        "                                    )\n",
        "                                ], width=4),\n",
        "                                dbc.Col([\n",
        "                                    html.Label(\"Time Range\"),\n",
        "                                    dcc.RangeSlider(\n",
        "                                        id='time-range',\n",
        "                                        marks={i: str(i) for i in range(0, 13, 3)},\n",
        "                                        min=0,\n",
        "                                        max=12,\n",
        "                                        value=[0, 12]\n",
        "                                    )\n",
        "                                ], width=4)\n",
        "                            ])\n",
        "                        ])\n",
        "                    ])\n",
        "                ])\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # KPI Cards\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Total Customers\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-total-customers\"),\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Average FX Volume\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-avg-volume\"),\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Churn Rate\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-churn-rate\"),\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Risk Score\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-risk-score\"),\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # Main Content Area\n",
        "            dbc.Row([\n",
        "                # Left Column - Charts\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Primary Analysis\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='main-chart')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=8),\n",
        "\n",
        "                # Right Column - Details\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Detailed Metrics\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='detail-chart')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=4)\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # Bottom Row - Additional Analysis\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Tabs([\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='model-performance')\n",
        "                        ], label=\"Model Performance\"),\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='feature-importance')\n",
        "                        ], label=\"Feature Importance\"),\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='customer-segments')\n",
        "                        ], label=\"Customer Segments\"),\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='risk-analysis')\n",
        "                        ], label=\"Risk Analysis\")\n",
        "                    ])\n",
        "                ])\n",
        "            ])\n",
        "        ], fluid=True)"
      ],
      "metadata": {
        "id": "EOsf3h4cnvYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def setup_callbacks(self):\n",
        "        @self.app.callback(\n",
        "            [Output('kpi-total-customers', 'children'),\n",
        "             Output('kpi-avg-volume', 'children'),\n",
        "             Output('kpi-churn-rate', 'children'),\n",
        "             Output('kpi-risk-score', 'children'),\n",
        "             Output('main-chart', 'figure'),\n",
        "             Output('detail-chart', 'figure'),\n",
        "             Output('model-performance', 'figure'),\n",
        "             Output('feature-importance', 'figure'),\n",
        "             Output('customer-segments', 'figure'),\n",
        "             Output('risk-analysis', 'figure')],\n",
        "            [Input('industry-filter', 'value'),\n",
        "             Input('analysis-type', 'value'),\n",
        "             Input('time-range', 'value')]\n",
        "        )\n",
        "        def update_dashboard(industry, analysis_type, time_range):\n",
        "            # Filter data based on selections\n",
        "            filtered_df = self.filter_data(industry, time_range)\n",
        "\n",
        "            # Calculate KPIs\n",
        "            kpis = self.calculate_kpis(filtered_df)\n",
        "\n",
        "            # Generate charts based on analysis type\n",
        "            if analysis_type == 'overview':\n",
        "                main_fig = self.create_overview_chart(filtered_df)\n",
        "                detail_fig = self.create_overview_details(filtered_df)\n",
        "            elif analysis_type == 'risk':\n",
        "                main_fig = self.create_risk_chart(filtered_df)\n",
        "                detail_fig = self.create_risk_details(filtered_df)\n",
        "            elif analysis_type == 'performance':\n",
        "                main_fig = self.create_performance_chart(filtered_df)\n",
        "                detail_fig = self.create_performance_details(filtered_df)\n",
        "            else:  # segmentation\n",
        "                main_fig = self.create_segmentation_chart(filtered_df)\n",
        "                detail_fig = self.create_segmentation_details(filtered_df)\n",
        "\n",
        "            # Create model performance visualizations\n",
        "            model_perf_fig = self.create_model_performance_chart()\n",
        "            feature_imp_fig = self.create_feature_importance_chart()\n",
        "            segment_fig = self.create_customer_segment_chart(filtered_df)\n",
        "            risk_fig = self.create_risk_analysis_chart(filtered_df)\n",
        "\n",
        "            return (\n",
        "                kpis['total_customers'],\n",
        "                f\"£{kpis['avg_volume']:,.2f}M\",\n",
        "                f\"{kpis['churn_rate']:.1%}\",\n",
        "                f\"{kpis['risk_score']:.1f}\",\n",
        "                main_fig,\n",
        "                detail_fig,\n",
        "                model_perf_fig,\n",
        "                feature_imp_fig,\n",
        "                segment_fig,\n",
        "                risk_fig\n",
        "            )\n",
        "\n",
        "    def filter_data(self, industry, time_range):\n",
        "        \"\"\"Filter data based on selections\"\"\"\n",
        "        df = self.data.copy()\n",
        "\n",
        "        if industry != 'All':\n",
        "            df = df[df['Industry'] == industry]\n",
        "\n",
        "        # Add time-based filtering if needed\n",
        "\n",
        "        return df\n",
        "\n",
        "    def calculate_kpis(self, df):\n",
        "        \"\"\"Calculate key performance indicators\"\"\"\n",
        "        return {\n",
        "            'total_customers': len(df),\n",
        "            'avg_volume': df['Monthly FX Volume (£M)'].mean(),\n",
        "            'churn_rate': df['churned'].mean(),\n",
        "            'risk_score': df['risk_score'].mean()\n",
        "        }\n",
        "\n",
        "    def create_overview_chart(self, df):\n",
        "        \"\"\"Create main overview chart\"\"\"\n",
        "        fig = px.scatter(\n",
        "            df,\n",
        "            x='Monthly FX Volume (£M)',\n",
        "            y='risk_score',\n",
        "            color='Industry',\n",
        "            size='Annual Revenue (£M)',\n",
        "            hover_data=['Company Name', 'churned'],\n",
        "            title='Customer Overview by Volume and Risk'\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            height=600,\n",
        "            template='plotly_white'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_overview_details(self, df):\n",
        "        \"\"\"Create detailed overview metrics\"\"\"\n",
        "        fig = make_subplots(rows=2, cols=1)\n",
        "\n",
        "        # Volume distribution\n",
        "        fig.add_trace(\n",
        "            go.Histogram(\n",
        "                x=df['Monthly FX Volume (£M)'],\n",
        "                name='Volume Distribution'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Risk distribution\n",
        "        fig.add_trace(\n",
        "            go.Histogram(\n",
        "                x=df['risk_score'],\n",
        "                name='Risk Distribution'\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        fig.update_layout(height=400, showlegend=True)\n",
        "        return fig\n",
        "\n",
        "    def create_risk_chart(self, df):\n",
        "        \"\"\"Create risk analysis chart\"\"\"\n",
        "        # Calculate risk metrics\n",
        "        df['composite_risk'] = (\n",
        "            df['risk_score'] * 0.4 +\n",
        "            df['Monthly FX Volume (£M)'] * 0.3 +\n",
        "            df['churned'] * 0.3\n",
        "        )\n",
        "\n",
        "        fig = px.scatter_3d(\n",
        "            df,\n",
        "            x='risk_score',\n",
        "            y='Monthly FX Volume (£M)',\n",
        "            z='composite_risk',\n",
        "            color='Industry',\n",
        "            size='Annual Revenue (£M)',\n",
        "            hover_data=['Company Name'],\n",
        "            title='3D Risk Analysis'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_risk_details(self, df):\n",
        "        \"\"\"Create detailed risk metrics\"\"\"\n",
        "        risk_by_industry = df.groupby('Industry')['risk_score'].mean().reset_index()\n",
        "\n",
        "        fig = px.bar(\n",
        "            risk_by_industry,\n",
        "            x='Industry',\n",
        "            y='risk_score',\n",
        "            title='Average Risk Score by Industry'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_performance_chart(self, df):\n",
        "        \"\"\"Create performance analysis chart\"\"\"\n",
        "        fig = px.scatter(\n",
        "            df,\n",
        "            x='Monthly FX Volume (£M)',\n",
        "            y='Annual Revenue (£M)',\n",
        "            color='churned',\n",
        "            size='risk_score',\n",
        "            facet_col='Industry',\n",
        "            title='Performance Analysis by Industry'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_performance_details(self, df):\n",
        "        \"\"\"Create detailed performance metrics\"\"\"\n",
        "        metrics = df.groupby('Industry').agg({\n",
        "            'Monthly FX Volume (£M)': 'mean',\n",
        "            'Annual Revenue (£M)': 'mean',\n",
        "            'churned': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        fig = px.bar(\n",
        "            metrics,\n",
        "            x='Industry',\n",
        "            y=['Monthly FX Volume (£M)', 'Annual Revenue (£M)', 'churned'],\n",
        "            title='Key Metrics by Industry',\n",
        "            barmode='group'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_model_performance_chart(self):\n",
        "        \"\"\"Create model performance visualization\"\"\"\n",
        "        # Get predictions from the pipeline\n",
        "        y_pred_proba = self.pipeline.best_model.predict_proba(self.pipeline.X_test)[:, 1]\n",
        "\n",
        "        # Calculate ROC curve\n",
        "        fpr, tpr, _ = roc_curve(self.pipeline.y_test, y_pred_proba)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        fig = go.Figure()\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=fpr, y=tpr,\n",
        "                name=f'ROC curve (AUC = {roc_auc:.2f})'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=[0, 1], y=[0, 1],\n",
        "                line=dict(dash='dash'),\n",
        "                name='Random'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        fig.update_layout(\n",
        "            title='Model ROC Curve',\n",
        "            xaxis_title='False Positive Rate',\n",
        "            yaxis_title='True Positive Rate'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_feature_importance_chart(self):\n",
        "        \"\"\"Create feature importance visualization\"\"\"\n",
        "        if hasattr(self.pipeline.best_model, 'feature_importances_'):\n",
        "            importance = pd.DataFrame({\n",
        "                'feature': self.pipeline.feature_columns,\n",
        "                'importance': self.pipeline.best_model.feature_importances_\n",
        "            }).sort_values('importance', ascending=True)\n",
        "\n",
        "            fig = px.bar(\n",
        "                importance.tail(10),\n",
        "                x='importance',\n",
        "                y='feature',\n",
        "                orientation='h',\n",
        "                title='Top 10 Feature Importance'\n",
        "            )\n",
        "\n",
        "            return fig\n",
        "        return go.Figure()\n",
        "\n",
        "    def create_customer_segment_chart(self, df):\n",
        "        \"\"\"Create customer segmentation visualization\"\"\"\n",
        "        # Perform clustering\n",
        "        features_for_clustering = [\n",
        "            'Monthly FX Volume (£M)',\n",
        "            'Annual Revenue (£M)',\n",
        "            'risk_score'\n",
        "        ]\n",
        "\n",
        "        X = StandardScaler().fit_transform(df[features_for_clustering])\n",
        "        kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "        df['Segment'] = kmeans.fit_predict(X)\n",
        "\n",
        "        fig = px.scatter_3d(\n",
        "            df,\n",
        "            x='Monthly FX Volume (£M)',\n",
        "            y='Annual Revenue (£M)',\n",
        "            z='risk_score',\n",
        "            color='Segment',\n",
        "            title='Customer Segments'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_risk_analysis_chart(self, df):\n",
        "        \"\"\"Create risk analysis visualization\"\"\"\n",
        "        # Calculate risk metrics\n",
        "        df['volume_risk'] = pd.qcut(df['Monthly FX Volume (£M)'], q=5, labels=['VL', 'L', 'M', 'H', 'VH'])\n",
        "        df['revenue_risk'] = pd.qcut(df['Annual Revenue (£M)'], q=5, labels=['VL', 'L', 'M', 'H', 'VH'])\n",
        "\n",
        "        risk_matrix = pd.crosstab(df['volume_risk'], df['revenue_risk'])\n",
        "\n",
        "        fig = px.imshow(\n",
        "            risk_matrix,\n",
        "            title='Risk Matrix: Volume vs Revenue',\n",
        "            labels=dict(x='Revenue Risk', y='Volume Risk')\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the dashboard\"\"\"\n",
        "        self.app.run_server(debug=True)"
      ],
      "metadata": {
        "id": "_yAwkYbHp1qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FXAnalyticsSuite:\n",
        "    def __init__(self, pipeline, results, data):\n",
        "        self.pipeline = pipeline\n",
        "        self.results = results\n",
        "        self.data = data\n",
        "        self.shap_values = None\n",
        "        self.calculate_shap_values()\n",
        "\n",
        "    def analyze_model_performance(self):\n",
        "        \"\"\"Analyze detailed model performance\"\"\"\n",
        "        try:\n",
        "            # Get feature importance\n",
        "            if hasattr(self.pipeline.best_model, 'feature_importances_'):\n",
        "                # Ensure feature names match the actual features used\n",
        "                feature_importance = pd.DataFrame({\n",
        "                    'feature': self.pipeline.feature_columns,\n",
        "                    'importance': self.pipeline.best_model.feature_importances_\n",
        "                })\n",
        "                feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "            else:\n",
        "                feature_importance = pd.DataFrame()\n",
        "\n",
        "            return {\n",
        "                'accuracy': accuracy_score(\n",
        "                    self.pipeline.y_test,\n",
        "                    self.pipeline.best_model.predict(self.pipeline.X_test)\n",
        "                ),\n",
        "                'feature_importance': feature_importance,\n",
        "                'shap_values': self.shap_values,\n",
        "                'model_type': type(self.pipeline.best_model).__name__,\n",
        "                'performance_metrics': {\n",
        "                    'precision': precision_score(\n",
        "                        self.pipeline.y_test,\n",
        "                        self.pipeline.best_model.predict(self.pipeline.X_test)\n",
        "                    ),\n",
        "                    'recall': recall_score(\n",
        "                        self.pipeline.y_test,\n",
        "                        self.pipeline.best_model.predict(self.pipeline.X_test)\n",
        "                    ),\n",
        "                    'roc_auc': roc_auc_score(\n",
        "                        self.pipeline.y_test,\n",
        "                        self.pipeline.best_model.predict_proba(self.pipeline.X_test)[:, 1]\n",
        "                    )\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error in model performance analysis: {str(e)}\")\n",
        "            return {\n",
        "                'accuracy': None,\n",
        "                'feature_importance': pd.DataFrame(),\n",
        "                'shap_values': None,\n",
        "                'model_type': None,\n",
        "                'performance_metrics': {}\n",
        "            }\n",
        "\n",
        "    def generate_insights_report(self):\n",
        "        \"\"\"Generate comprehensive insights report\"\"\"\n",
        "        try:\n",
        "            insights = {\n",
        "                'model_performance': self.analyze_model_performance(),\n",
        "                'customer_segments': self.analyze_customer_segments(),\n",
        "                'risk_profiles': self.analyze_risk_profiles(),\n",
        "                'recommendations': self.generate_recommendations()\n",
        "            }\n",
        "            return insights\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating insights report: {str(e)}\")\n",
        "            return {}"
      ],
      "metadata": {
        "id": "8Ow8nvMHsyHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelPipeline:\n",
        "    def prepare_features(self):\n",
        "        try:\n",
        "            logger.info(\"Preparing features for modeling...\")\n",
        "\n",
        "            # Select features for modeling\n",
        "            self.feature_columns = [\n",
        "                'monthly_volume', 'spot_ratio', 'forward_ratio',\n",
        "                'login_frequency', 'support_tickets', 'platform_usage_hours',\n",
        "                'credit_score', 'risk_score', 'volume_per_login',\n",
        "                'tickets_per_volume', 'revenue_per_employee',\n",
        "                'risk_volume_interaction'\n",
        "            ]\n",
        "\n",
        "            # Add dummy columns\n",
        "            dummy_columns = [col for col in self.df.columns if 'industry_' in col or 'company_size_' in col]\n",
        "            self.feature_columns.extend(dummy_columns)\n",
        "\n",
        "            # Verify all columns exist\n",
        "            missing_cols = [col for col in self.feature_columns if col not in self.df.columns]\n",
        "            if missing_cols:\n",
        "                raise ValueError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "            # Prepare X and y\n",
        "            X = self.df[self.feature_columns]\n",
        "            y = self.df['churned']\n",
        "\n",
        "            # Scale features\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "            logger.info(f\"Prepared {len(self.feature_columns)} features for modeling\")\n",
        "            return X_scaled, y, self.feature_columns\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature preparation: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_models(self, X, y):\n",
        "        try:\n",
        "            logger.info(\"Training models...\")\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Store test data\n",
        "            self.X_test = X_test\n",
        "            self.y_test = y_test\n",
        "\n",
        "            # Initialize models\n",
        "            models = {\n",
        "                'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "                'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "            }\n",
        "\n",
        "            # Train and evaluate models\n",
        "            results = {}\n",
        "            for name, model in models.items():\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "                results[name] = {\n",
        "                    'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
        "                    'model': model,\n",
        "                    'predictions': y_pred_proba\n",
        "                }\n",
        "\n",
        "                logger.info(f\"{name} - AUC ROC: {results[name]['auc_roc']:.3f}\")\n",
        "\n",
        "            # Select best model\n",
        "            best_model_name = max(results.items(), key=lambda x: x[1]['auc_roc'])[0]\n",
        "            self.best_model = results[best_model_name]['model']\n",
        "\n",
        "            logger.info(f\"Best model: {best_model_name}\")\n",
        "            return results, X_test, y_test\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in model training: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "bsHxLMR5tUC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChurnModelPipeline:\n",
        "    def __init__(self, df):  # Add initialization with df parameter\n",
        "        self.df = df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = PCA(n_components=0.95)\n",
        "        self.feature_importance = None\n",
        "        self.best_model = None\n",
        "        self.feature_columns = []\n",
        "        self.X_test = None\n",
        "        self.y_test = None\n",
        "        logger.info(\"ChurnModelPipeline initialized\")\n",
        "\n",
        "    def engineer_features(self):\n",
        "        try:\n",
        "            logger.info(\"Starting feature engineering...\")\n",
        "\n",
        "            # Create ratio features\n",
        "            self.df['volume_per_login'] = self.df['monthly_volume'] / self.df['login_frequency'].clip(lower=1)\n",
        "            self.df['tickets_per_volume'] = self.df['support_tickets'] / self.df['monthly_volume'].clip(lower=1)\n",
        "            self.df['revenue_per_employee'] = self.df['annual_revenue'] / self.df['employees'].clip(lower=1)\n",
        "\n",
        "            # Create interaction features\n",
        "            self.df['risk_volume_interaction'] = self.df['risk_score'] * self.df['monthly_volume']\n",
        "\n",
        "            # Create categorical encodings\n",
        "            categorical_columns = ['industry', 'company_size']\n",
        "            for col in categorical_columns:\n",
        "                dummies = pd.get_dummies(self.df[col], prefix=col)\n",
        "                self.df = pd.concat([self.df, dummies], axis=1)\n",
        "\n",
        "            logger.info(\"Feature engineering completed successfully\")\n",
        "            return self.df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature engineering: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def prepare_features(self):\n",
        "        try:\n",
        "            logger.info(\"Preparing features for modeling...\")\n",
        "\n",
        "            # Select features for modeling\n",
        "            self.feature_columns = [\n",
        "                'monthly_volume', 'spot_ratio', 'forward_ratio',\n",
        "                'login_frequency', 'support_tickets', 'platform_usage_hours',\n",
        "                'credit_score', 'risk_score', 'volume_per_login',\n",
        "                'tickets_per_volume', 'revenue_per_employee',\n",
        "                'risk_volume_interaction'\n",
        "            ]\n",
        "\n",
        "            # Add dummy columns\n",
        "            dummy_columns = [col for col in self.df.columns if 'industry_' in col or 'company_size_' in col]\n",
        "            self.feature_columns.extend(dummy_columns)\n",
        "\n",
        "            # Verify all columns exist\n",
        "            missing_cols = [col for col in self.feature_columns if col not in self.df.columns]\n",
        "            if missing_cols:\n",
        "                raise ValueError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "            # Prepare X and y\n",
        "            X = self.df[self.feature_columns]\n",
        "            y = self.df['churned']\n",
        "\n",
        "            # Scale features\n",
        "            X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "            logger.info(f\"Prepared {len(self.feature_columns)} features for modeling\")\n",
        "            return X_scaled, y, self.feature_columns\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in feature preparation: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def apply_pca(self, X):\n",
        "        try:\n",
        "            logger.info(\"Applying PCA...\")\n",
        "\n",
        "            X_pca = self.pca.fit_transform(X)\n",
        "            explained_variance = np.cumsum(self.pca.explained_variance_ratio_)\n",
        "\n",
        "            logger.info(f\"Number of components selected: {self.pca.n_components_}\")\n",
        "            logger.info(f\"Total variance explained: {explained_variance[-1]:.3f}\")\n",
        "\n",
        "            return X_pca, explained_variance\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in PCA application: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def train_models(self, X, y):\n",
        "        try:\n",
        "            logger.info(\"Training models...\")\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Store test data\n",
        "            self.X_test = X_test\n",
        "            self.y_test = y_test\n",
        "\n",
        "            # Initialize models\n",
        "            models = {\n",
        "                'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "                'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "            }\n",
        "\n",
        "            # Train and evaluate models\n",
        "            results = {}\n",
        "            for name, model in models.items():\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "                results[name] = {\n",
        "                    'auc_roc': roc_auc_score(y_test, y_pred_proba),\n",
        "                    'model': model,\n",
        "                    'predictions': y_pred_proba\n",
        "                }\n",
        "\n",
        "                logger.info(f\"{name} - AUC ROC: {results[name]['auc_roc']:.3f}\")\n",
        "\n",
        "            # Select best model\n",
        "            best_model_name = max(results.items(), key=lambda x: x[1]['auc_roc'])[0]\n",
        "            self.best_model = results[best_model_name]['model']\n",
        "\n",
        "            logger.info(f\"Best model: {best_model_name}\")\n",
        "            return results, X_test, y_test\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in model training: {str(e)}\")\n",
        "            raise"
      ],
      "metadata": {
        "id": "IkvSGpcxtpRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_insights_report(self):\n",
        "    \"\"\"Generate comprehensive insights report\"\"\"\n",
        "    try:\n",
        "        logger.info(\"Generating insights report...\")\n",
        "\n",
        "        insights = {\n",
        "            'model_performance': self.analyze_model_performance(),\n",
        "            'customer_segments': self.analyze_customer_segments(),\n",
        "            'risk_profiles': self.analyze_risk_profiles(),\n",
        "            'recommendations': self.generate_recommendations(),\n",
        "            'summary_statistics': self.generate_summary_statistics()\n",
        "        }\n",
        "\n",
        "        logger.info(\"Insights report generated successfully\")\n",
        "        return insights\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating insights report: {e}\")\n",
        "        return {\n",
        "            'model_performance': None,\n",
        "            'customer_segments': None,\n",
        "            'risk_profiles': None,\n",
        "            'recommendations': None,\n",
        "            'summary_statistics': None\n",
        "        }\n",
        "\n",
        "def generate_summary_statistics(self):\n",
        "    \"\"\"Generate summary statistics for the dataset\"\"\"\n",
        "    try:\n",
        "        summary = {\n",
        "            'total_customers': len(self.data),\n",
        "            'average_monthly_volume': self.data['monthly_volume'].mean(),\n",
        "            'average_risk_score': self.data['risk_score'].mean(),\n",
        "            'churn_rate': self.data['churned'].mean(),\n",
        "            'industry_distribution': self.data['industry'].value_counts().to_dict(),\n",
        "            'risk_distribution': {\n",
        "                'high_risk': len(self.data[self.data['risk_score'] > 75]),\n",
        "                'medium_risk': len(self.data[(self.data['risk_score'] > 25) & (self.data['risk_score'] <= 75)]),\n",
        "                'low_risk': len(self.data[self.data['risk_score'] <= 25])\n",
        "            },\n",
        "            'volume_statistics': {\n",
        "                'mean': self.data['monthly_volume'].mean(),\n",
        "                'median': self.data['monthly_volume'].median(),\n",
        "                'std': self.data['monthly_volume'].std(),\n",
        "                'min': self.data['monthly_volume'].min(),\n",
        "                'max': self.data['monthly_volume'].max()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Add correlation analysis\n",
        "        numeric_columns = self.data.select_dtypes(include=[np.number]).columns\n",
        "        correlations = self.data[numeric_columns].corr()\n",
        "\n",
        "        # Get top correlations with monthly_volume and risk_score\n",
        "        volume_correlations = correlations['monthly_volume'].sort_values(ascending=False)[:5]\n",
        "        risk_correlations = correlations['risk_score'].sort_values(ascending=False)[:5]\n",
        "\n",
        "        summary['correlations'] = {\n",
        "            'volume_correlations': volume_correlations.to_dict(),\n",
        "            'risk_correlations': risk_correlations.to_dict()\n",
        "        }\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating summary statistics: {e}\")\n",
        "        return None\n",
        "\n",
        "def print_insights_summary(self, insights):\n",
        "    \"\"\"Print a summary of the insights\"\"\"\n",
        "    try:\n",
        "        print(\"\\n=== INSIGHTS SUMMARY ===\")\n",
        "\n",
        "        # Model Performance\n",
        "        if insights['model_performance']:\n",
        "            print(\"\\nModel Performance:\")\n",
        "            print(f\"Accuracy: {insights['model_performance']['accuracy']:.3f}\")\n",
        "            print(f\"ROC AUC: {insights['model_performance']['performance_metrics']['roc_auc']:.3f}\")\n",
        "\n",
        "            if not insights['model_performance']['feature_importance'].empty:\n",
        "                print(\"\\nTop 5 Important Features:\")\n",
        "                print(insights['model_performance']['feature_importance'].head())\n",
        "\n",
        "        # Customer Segments\n",
        "        if insights['customer_segments']:\n",
        "            print(\"\\nCustomer Segments:\")\n",
        "            print(f\"Number of segments: {len(insights['customer_segments']['profiles'])}\")\n",
        "            print(\"\\nSegment Profiles:\")\n",
        "            print(insights['customer_segments']['profiles'])\n",
        "\n",
        "        # Risk Profiles\n",
        "        if insights['risk_profiles']:\n",
        "            print(\"\\nRisk Analysis:\")\n",
        "            print(f\"Number of high-risk clients: {len(insights['risk_profiles']['high_risk_clients'])}\")\n",
        "            print(\"\\nRisk by Industry:\")\n",
        "            print(insights['risk_profiles']['risk_by_industry'])\n",
        "\n",
        "        # Recommendations\n",
        "        if insights['recommendations']:\n",
        "            print(\"\\nRecommendations:\")\n",
        "            for rec in insights['recommendations']:\n",
        "                print(f\"\\n{rec['type']}:\")\n",
        "                print(f\"Description: {rec['description']}\")\n",
        "                print(f\"Action: {rec['action']}\")\n",
        "                print(f\"Number of clients: {len(rec['clients'])}\")\n",
        "\n",
        "        # Summary Statistics\n",
        "        if insights['summary_statistics']:\n",
        "            print(\"\\nSummary Statistics:\")\n",
        "            print(f\"Total Customers: {insights['summary_statistics']['total_customers']}\")\n",
        "            print(f\"Average Monthly Volume: £{insights['summary_statistics']['average_monthly_volume']:.2f}M\")\n",
        "            print(f\"Churn Rate: {insights['summary_statistics']['churn_rate']:.2%}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error printing insights summary: {e}\")"
      ],
      "metadata": {
        "id": "eEe6QNiHvX10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_complete_analysis():\n",
        "    try:\n",
        "        # Generate data\n",
        "        print(\"Generating and processing data...\")\n",
        "        df = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        # Initialize and run pipeline\n",
        "        print(\"Running model pipeline...\")\n",
        "        pipeline = ChurnModelPipeline(df)\n",
        "        df_engineered = pipeline.engineer_features()\n",
        "        X, y, feature_columns = pipeline.prepare_features()\n",
        "        X_pca, explained_variance = pipeline.apply_pca(X)\n",
        "        results, X_test, y_test = pipeline.train_models(X_pca, y)\n",
        "\n",
        "        # Initialize analytics suite\n",
        "        print(\"Initializing analytics suite...\")\n",
        "        analytics_suite = FXAnalyticsSuite(pipeline, results, df)\n",
        "\n",
        "        # Generate insights\n",
        "        print(\"Generating insights...\")\n",
        "        insights = analytics_suite.generate_insights_report()\n",
        "\n",
        "        # Print insights summary\n",
        "        analytics_suite.print_insights_summary(insights)\n",
        "\n",
        "        # Launch dashboard\n",
        "        print(\"\\nLaunching dashboard...\")\n",
        "        dashboard = analytics_suite.launch_dashboard()\n",
        "        dashboard.run()\n",
        "\n",
        "        return analytics_suite, insights, dashboard\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None, None"
      ],
      "metadata": {
        "id": "7ebXblSOvYMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FXAnalyticsSuite:\n",
        "    def __init__(self, pipeline, results, data):\n",
        "        self.pipeline = pipeline\n",
        "        self.results = results\n",
        "        self.data = data\n",
        "        self.shap_values = None\n",
        "        self.feature_columns = self.pipeline.feature_columns  # Ensure feature columns are available\n",
        "\n",
        "    def analyze_model_performance(self):\n",
        "        \"\"\"Analyze detailed model performance\"\"\"\n",
        "        try:\n",
        "            # Get predictions\n",
        "            y_pred = self.pipeline.best_model.predict(self.pipeline.X_test)\n",
        "            y_pred_proba = self.pipeline.best_model.predict_proba(self.pipeline.X_test)[:, 1]\n",
        "\n",
        "            # Basic metrics\n",
        "            performance = {\n",
        "                'accuracy': accuracy_score(self.pipeline.y_test, y_pred),\n",
        "                'roc_auc': roc_auc_score(self.pipeline.y_test, y_pred_proba),\n",
        "                'precision': precision_score(self.pipeline.y_test, y_pred),\n",
        "                'recall': recall_score(self.pipeline.y_test, y_pred)\n",
        "            }\n",
        "\n",
        "            # Feature importance (ensure lengths match)\n",
        "            if hasattr(self.pipeline.best_model, 'feature_importances_'):\n",
        "                importance_df = pd.DataFrame({\n",
        "                    'feature': self.feature_columns,\n",
        "                    'importance': self.pipeline.best_model.feature_importances_\n",
        "                })\n",
        "                performance['feature_importance'] = importance_df.sort_values('importance', ascending=False)\n",
        "\n",
        "            return performance\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in model performance analysis: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def analyze_customer_segments(self):\n",
        "        \"\"\"Perform customer segmentation analysis\"\"\"\n",
        "        try:\n",
        "            # Select features for clustering\n",
        "            features_for_clustering = ['monthly_volume', 'risk_score']\n",
        "\n",
        "            # Scale features\n",
        "            scaler = StandardScaler()\n",
        "            X_cluster = scaler.fit_transform(self.data[features_for_clustering])\n",
        "\n",
        "            # Perform clustering\n",
        "            kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "            self.data['Segment'] = kmeans.fit_predict(X_cluster)\n",
        "\n",
        "            # Calculate segment profiles\n",
        "            segment_profiles = self.data.groupby('Segment').agg({\n",
        "                'monthly_volume': 'mean',\n",
        "                'risk_score': 'mean',\n",
        "                'churned': 'mean'\n",
        "            }).round(2)\n",
        "\n",
        "            return {\n",
        "                'profiles': segment_profiles,\n",
        "                'segment_sizes': self.data['Segment'].value_counts()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in customer segmentation: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def analyze_risk_profiles(self):\n",
        "        \"\"\"Analyze risk profiles\"\"\"\n",
        "        try:\n",
        "            risk_profiles = {\n",
        "                'high_risk_count': len(self.data[self.data['risk_score'] > 75]),\n",
        "                'risk_by_industry': self.data.groupby('industry')['risk_score'].mean(),\n",
        "                'risk_distribution': self.data['risk_score'].describe()\n",
        "            }\n",
        "            return risk_profiles\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in risk profile analysis: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def generate_recommendations(self):\n",
        "        \"\"\"Generate recommendations\"\"\"\n",
        "        try:\n",
        "            recommendations = []\n",
        "\n",
        "            # High-risk clients\n",
        "            high_risk = self.data[self.data['risk_score'] > 75]\n",
        "            if len(high_risk) > 0:\n",
        "                recommendations.append({\n",
        "                    'type': 'High Risk Alert',\n",
        "                    'count': len(high_risk),\n",
        "                    'action': 'Immediate review required'\n",
        "                })\n",
        "\n",
        "            # Growth opportunities\n",
        "            low_volume = self.data[self.data['monthly_volume'] < self.data['monthly_volume'].quantile(0.25)]\n",
        "            if len(low_volume) > 0:\n",
        "                recommendations.append({\n",
        "                    'type': 'Growth Opportunity',\n",
        "                    'count': len(low_volume),\n",
        "                    'action': 'Develop growth strategy'\n",
        "                })\n",
        "\n",
        "            return recommendations\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating recommendations: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def generate_summary_statistics(self):\n",
        "        \"\"\"Generate summary statistics\"\"\"\n",
        "        try:\n",
        "            summary = {\n",
        "                'total_customers': len(self.data),\n",
        "                'average_volume': self.data['monthly_volume'].mean(),\n",
        "                'churn_rate': self.data['churned'].mean(),\n",
        "                'risk_score_avg': self.data['risk_score'].mean()\n",
        "            }\n",
        "            return summary\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating summary statistics: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def generate_insights_report(self):\n",
        "        \"\"\"Generate comprehensive insights report\"\"\"\n",
        "        try:\n",
        "            insights = {\n",
        "                'model_performance': self.analyze_model_performance(),\n",
        "                'customer_segments': self.analyze_customer_segments(),\n",
        "                'risk_profiles': self.analyze_risk_profiles(),\n",
        "                'recommendations': self.generate_recommendations(),\n",
        "                'summary_statistics': self.generate_summary_statistics()\n",
        "            }\n",
        "            return insights\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating insights report: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def print_insights_summary(self, insights):\n",
        "        \"\"\"Print insights summary\"\"\"\n",
        "        try:\n",
        "            if insights is None:\n",
        "                print(\"No insights available.\")\n",
        "                return\n",
        "\n",
        "            print(\"\\n=== INSIGHTS SUMMARY ===\")\n",
        "\n",
        "            # Print model performance\n",
        "            if insights['model_performance']:\n",
        "                print(\"\\nModel Performance:\")\n",
        "                perf = insights['model_performance']\n",
        "                print(f\"Accuracy: {perf['accuracy']:.3f}\")\n",
        "                print(f\"ROC AUC: {perf['roc_auc']:.3f}\")\n",
        "                print(f\"Precision: {perf['precision']:.3f}\")\n",
        "                print(f\"Recall: {perf['recall']:.3f}\")\n",
        "\n",
        "            # Print customer segments\n",
        "            if insights['customer_segments']:\n",
        "                print(\"\\nCustomer Segments:\")\n",
        "                print(insights['customer_segments']['profiles'])\n",
        "\n",
        "            # Print risk profiles\n",
        "            if insights['risk_profiles']:\n",
        "                print(\"\\nRisk Profiles:\")\n",
        "                print(f\"High Risk Clients: {insights['risk_profiles']['high_risk_count']}\")\n",
        "\n",
        "            # Print recommendations\n",
        "            if insights['recommendations']:\n",
        "                print(\"\\nRecommendations:\")\n",
        "                for rec in insights['recommendations']:\n",
        "                    print(f\"- {rec['type']}: {rec['action']} ({rec['count']} clients)\")\n",
        "\n",
        "            # Print summary statistics\n",
        "            if insights['summary_statistics']:\n",
        "                print(\"\\nSummary Statistics:\")\n",
        "                stats = insights['summary_statistics']\n",
        "                print(f\"Total Customers: {stats['total_customers']}\")\n",
        "                print(f\"Average Volume: £{stats['average_volume']:.2f}M\")\n",
        "                print(f\"Churn Rate: {stats['churn_rate']:.2%}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error printing insights summary: {str(e)}\")\n",
        "\n",
        "def run_complete_analysis():\n",
        "    try:\n",
        "        # Generate data\n",
        "        print(\"Generating and processing data...\")\n",
        "        df = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        # Initialize and run pipeline\n",
        "        print(\"Running model pipeline...\")\n",
        "        pipeline = ChurnModelPipeline(df)\n",
        "        df_engineered = pipeline.engineer_features()\n",
        "        X, y, feature_columns = pipeline.prepare_features()\n",
        "        X_pca, explained_variance = pipeline.apply_pca(X)\n",
        "        results, X_test, y_test = pipeline.train_models(X_pca, y)\n",
        "\n",
        "        # Initialize analytics suite\n",
        "        print(\"Initializing analytics suite...\")\n",
        "        analytics_suite = FXAnalyticsSuite(pipeline, results, df)\n",
        "\n",
        "        # Generate insights\n",
        "        print(\"Generating insights...\")\n",
        "        insights = analytics_suite.generate_insights_report()\n",
        "\n",
        "        # Print insights summary\n",
        "        analytics_suite.print_insights_summary(insights)\n",
        "\n",
        "        return analytics_suite, insights\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analytics_suite, insights = run_complete_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlUCIVNIwFnx",
        "outputId": "b7e13314-33f1-45ed-c33f-99ed86632759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and processing data...\n",
            "Running model pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in model performance analysis: name 'accuracy_score' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing analytics suite...\n",
            "Generating insights...\n",
            "\n",
            "=== INSIGHTS SUMMARY ===\n",
            "\n",
            "Customer Segments:\n",
            "         monthly_volume  risk_score  churned\n",
            "Segment                                     \n",
            "0                 24.39       25.37     0.20\n",
            "1                 77.97       75.53     0.20\n",
            "2                 25.33       74.56     0.19\n",
            "3                 73.01       28.28     0.15\n",
            "\n",
            "Risk Profiles:\n",
            "High Risk Clients: 250\n",
            "\n",
            "Recommendations:\n",
            "- High Risk Alert: Immediate review required (250 clients)\n",
            "- Growth Opportunity: Develop growth strategy (250 clients)\n",
            "\n",
            "Summary Statistics:\n",
            "Total Customers: 1000\n",
            "Average Volume: £49.23M\n",
            "Churn Rate: 18.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComprehensiveDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__, external_stylesheets=[dbc.themes.FLATLY])\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Header\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    html.H1(\"FX Sales Analytics Dashboard\",\n",
        "                           className=\"text-center mb-4\")\n",
        "                ])\n",
        "            ]),\n",
        "\n",
        "            # Filters\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    html.Label(\"Select Industry\"),\n",
        "                    dcc.Dropdown(\n",
        "                        id='industry-filter',\n",
        "                        options=[{'label': x, 'value': x}\n",
        "                                for x in self.analytics_suite.data['industry'].unique()],\n",
        "                        value=None\n",
        "                    )\n",
        "                ], width=4),\n",
        "                dbc.Col([\n",
        "                    html.Label(\"Risk Level\"),\n",
        "                    dcc.RangeSlider(\n",
        "                        id='risk-slider',\n",
        "                        min=0,\n",
        "                        max=100,\n",
        "                        step=5,\n",
        "                        marks={i: str(i) for i in range(0, 101, 20)},\n",
        "                        value=[0, 100]\n",
        "                    )\n",
        "                ], width=8)\n",
        "            ]),\n",
        "\n",
        "            # KPI Cards\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Total Clients\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-total-clients\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Average Volume\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-avg-volume\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Churn Rate\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-churn-rate\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Risk Score\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-risk-score\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3)\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # Main Charts\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(id='volume-risk-scatter')\n",
        "                ], width=6),\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(id='industry-distribution')\n",
        "                ], width=6)\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # Additional Charts\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(id='risk-distribution')\n",
        "                ], width=6),\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(id='churn-analysis')\n",
        "                ], width=6)\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        @self.app.callback(\n",
        "            [Output('kpi-total-clients', 'children'),\n",
        "             Output('kpi-avg-volume', 'children'),\n",
        "             Output('kpi-churn-rate', 'children'),\n",
        "             Output('kpi-risk-score', 'children'),\n",
        "             Output('volume-risk-scatter', 'figure'),\n",
        "             Output('industry-distribution', 'figure'),\n",
        "             Output('risk-distribution', 'figure'),\n",
        "             Output('churn-analysis', 'figure')],\n",
        "            [Input('industry-filter', 'value'),\n",
        "             Input('risk-slider', 'value')]\n",
        "        )\n",
        "        def update_dashboard(selected_industry, risk_range):\n",
        "            # Filter data\n",
        "            df = self.analytics_suite.data.copy()\n",
        "            if selected_industry:\n",
        "                df = df[df['industry'] == selected_industry]\n",
        "            df = df[\n",
        "                (df['risk_score'] >= risk_range[0]) &\n",
        "                (df['risk_score'] <= risk_range[1])\n",
        "            ]\n",
        "\n",
        "            # Calculate KPIs\n",
        "            kpis = self.calculate_kpis(df)\n",
        "\n",
        "            # Create figures\n",
        "            scatter_fig = self.create_scatter_plot(df)\n",
        "            industry_fig = self.create_industry_distribution(df)\n",
        "            risk_fig = self.create_risk_distribution(df)\n",
        "            churn_fig = self.create_churn_analysis(df)\n",
        "\n",
        "            return (\n",
        "                f\"{len(df):,}\",\n",
        "                f\"£{df['monthly_volume'].mean():.1f}M\",\n",
        "                f\"{df['churned'].mean():.1%}\",\n",
        "                f\"{df['risk_score'].mean():.1f}\",\n",
        "                scatter_fig,\n",
        "                industry_fig,\n",
        "                risk_fig,\n",
        "                churn_fig\n",
        "            )\n",
        "\n",
        "    def calculate_kpis(self, df):\n",
        "        return {\n",
        "            'total_clients': len(df),\n",
        "            'avg_volume': df['monthly_volume'].mean(),\n",
        "            'churn_rate': df['churned'].mean(),\n",
        "            'risk_score': df['risk_score'].mean()\n",
        "        }\n",
        "\n",
        "    def create_scatter_plot(self, df):\n",
        "        return px.scatter(\n",
        "            df,\n",
        "            x='monthly_volume',\n",
        "            y='risk_score',\n",
        "            color='industry',\n",
        "            size='monthly_volume',\n",
        "            hover_data=['churned'],\n",
        "            title='Volume vs Risk Score'\n",
        "        )\n",
        "\n",
        "    def create_industry_distribution(self, df):\n",
        "        return px.bar(\n",
        "            df['industry'].value_counts().reset_index(),\n",
        "            x='index',\n",
        "            y='industry',\n",
        "            title='Industry Distribution'\n",
        "        )\n",
        "\n",
        "    def create_risk_distribution(self, df):\n",
        "        return px.histogram(\n",
        "            df,\n",
        "            x='risk_score',\n",
        "            nbins=20,\n",
        "            title='Risk Score Distribution'\n",
        "        )\n",
        "\n",
        "    def create_churn_analysis(self, df):\n",
        "        churn_by_industry = df.groupby('industry')['churned'].mean().reset_index()\n",
        "        return px.bar(\n",
        "            churn_by_industry,\n",
        "            x='industry',\n",
        "            y='churned',\n",
        "            title='Churn Rate by Industry'\n",
        "        )\n",
        "\n",
        "    def run(self):\n",
        "        self.app.run_server(debug=True)\n",
        "\n",
        "def run_complete_analysis():\n",
        "    try:\n",
        "        # Generate data\n",
        "        print(\"Generating and processing data...\")\n",
        "        df = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        # Initialize and run pipeline\n",
        "        print(\"Running model pipeline...\")\n",
        "        pipeline = ChurnModelPipeline(df)\n",
        "        df_engineered = pipeline.engineer_features()\n",
        "        X, y, feature_columns = pipeline.prepare_features()\n",
        "        X_pca, explained_variance = pipeline.apply_pca(X)\n",
        "        results, X_test, y_test = pipeline.train_models(X_pca, y)\n",
        "\n",
        "        # Initialize analytics suite\n",
        "        print(\"Initializing analytics suite...\")\n",
        "        analytics_suite = FXAnalyticsSuite(pipeline, results, df)\n",
        "\n",
        "        # Generate insights\n",
        "        print(\"Generating insights...\")\n",
        "        insights = analytics_suite.generate_insights_report()\n",
        "\n",
        "        # Print insights summary\n",
        "        analytics_suite.print_insights_summary(insights)\n",
        "\n",
        "        # Create and launch dashboard\n",
        "        print(\"\\nLaunching dashboard...\")\n",
        "        dashboard = ComprehensiveDashboard(analytics_suite)\n",
        "        dashboard.run()\n",
        "\n",
        "        return analytics_suite, insights, dashboard\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analytics_suite, insights, dashboard = run_complete_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QYHn8ngSwvKl",
        "outputId": "86e4e83f-61d4-4481-df74-a39c2868fa2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and processing data...\n",
            "Running model pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in model performance analysis: name 'accuracy_score' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing analytics suite...\n",
            "Generating insights...\n",
            "\n",
            "=== INSIGHTS SUMMARY ===\n",
            "\n",
            "Customer Segments:\n",
            "         monthly_volume  risk_score  churned\n",
            "Segment                                     \n",
            "0                 24.39       25.37     0.20\n",
            "1                 77.97       75.53     0.20\n",
            "2                 25.33       74.56     0.19\n",
            "3                 73.01       28.28     0.15\n",
            "\n",
            "Risk Profiles:\n",
            "High Risk Clients: 250\n",
            "\n",
            "Recommendations:\n",
            "- High Risk Alert: Immediate review required (250 clients)\n",
            "- Growth Opportunity: Develop growth strategy (250 clients)\n",
            "\n",
            "Summary Statistics:\n",
            "Total Customers: 1000\n",
            "Average Volume: £49.23M\n",
            "Churn Rate: 18.80%\n",
            "\n",
            "Launching dashboard...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_complete_analysis():\n",
        "    try:\n",
        "        # Generate data\n",
        "        print(\"Generating and processing data...\")\n",
        "        df = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        # Initialize and run pipeline\n",
        "        print(\"Running model pipeline...\")\n",
        "        pipeline = ChurnModelPipeline(df)\n",
        "        df_engineered = pipeline.engineer_features()\n",
        "        X, y, feature_columns = pipeline.prepare_features()\n",
        "        X_pca, explained_variance = pipeline.apply_pca(X)\n",
        "        results, X_test, y_test = pipeline.train_models(X_pca, y)\n",
        "\n",
        "        # Initialize analytics suite\n",
        "        print(\"Initializing analytics suite...\")\n",
        "        analytics_suite = FXAnalyticsSuite(pipeline, results, df)\n",
        "\n",
        "        # Generate insights\n",
        "        print(\"Generating insights...\")\n",
        "        insights = analytics_suite.generate_insights_report()\n",
        "\n",
        "        # Print insights summary\n",
        "        analytics_suite.print_insights_summary(insights)\n",
        "\n",
        "        # Create dashboard\n",
        "        print(\"\\nCreating dashboard...\")\n",
        "        dashboard = ComprehensiveDashboard(analytics_suite)\n",
        "\n",
        "        return analytics_suite, insights, dashboard\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "# Separate function to run the dashboard\n",
        "def run_dashboard(dashboard):\n",
        "    if dashboard is not None:\n",
        "        print(\"Launching dashboard...\")\n",
        "        dashboard.run()\n",
        "    else:\n",
        "        print(\"Dashboard creation failed.\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    analytics_suite, insights, dashboard = run_complete_analysis()\n",
        "    if all(v is not None for v in [analytics_suite, insights, dashboard]):\n",
        "        run_dashboard(dashboard)"
      ],
      "metadata": {
        "id": "UAdfTqnTyd9U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c5fe1f6-a551-4e23-bc0e-48db7db7c2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and processing data...\n",
            "Running model pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in model performance analysis: name 'accuracy_score' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing analytics suite...\n",
            "Generating insights...\n",
            "\n",
            "=== INSIGHTS SUMMARY ===\n",
            "\n",
            "Customer Segments:\n",
            "         monthly_volume  risk_score  churned\n",
            "Segment                                     \n",
            "0                 24.39       25.37     0.20\n",
            "1                 77.97       75.53     0.20\n",
            "2                 25.33       74.56     0.19\n",
            "3                 73.01       28.28     0.15\n",
            "\n",
            "Risk Profiles:\n",
            "High Risk Clients: 250\n",
            "\n",
            "Recommendations:\n",
            "- High Risk Alert: Immediate review required (250 clients)\n",
            "- Growth Opportunity: Develop growth strategy (250 clients)\n",
            "\n",
            "Summary Statistics:\n",
            "Total Customers: 1000\n",
            "Average Volume: £49.23M\n",
            "Churn Rate: 18.80%\n",
            "\n",
            "Creating dashboard...\n",
            "Launching dashboard...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_complete_analysis():\n",
        "    try:\n",
        "        # Generate data\n",
        "        print(\"Generating and processing data...\")\n",
        "        df = generate_fx_customer_data(n_samples=1000)\n",
        "\n",
        "        # Initialize and run pipeline\n",
        "        print(\"Running model pipeline...\")\n",
        "        pipeline = ChurnModelPipeline(df)\n",
        "        df_engineered = pipeline.engineer_features()\n",
        "        X, y, feature_columns = pipeline.prepare_features()\n",
        "        X_pca, explained_variance = pipeline.apply_pca(X)\n",
        "        results, X_test, y_test = pipeline.train_models(X_pca, y)\n",
        "\n",
        "        # Initialize analytics suite\n",
        "        print(\"Initializing analytics suite...\")\n",
        "        analytics_suite = FXAnalyticsSuite(pipeline, results, df)\n",
        "\n",
        "        # Generate insights\n",
        "        print(\"Generating insights...\")\n",
        "        insights = analytics_suite.generate_insights_report()\n",
        "\n",
        "        # Print insights summary\n",
        "        analytics_suite.print_insights_summary(insights)\n",
        "\n",
        "        # Create dashboard\n",
        "        print(\"\\nCreating dashboard...\")\n",
        "        dashboard = ComprehensiveDashboard(analytics_suite)\n",
        "\n",
        "        return analytics_suite, insights, dashboard\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        return None, None, None\n",
        "\n",
        "# Separate function to run the dashboard\n",
        "def run_dashboard(dashboard):\n",
        "    if dashboard is not None:\n",
        "        print(\"Launching dashboard...\")\n",
        "        dashboard.run()\n",
        "    else:\n",
        "        print(\"Dashboard creation failed.\")\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    analytics_suite, insights, dashboard = run_complete_analysis()\n",
        "    if all(v is not None for v in [analytics_suite, insights, dashboard]):\n",
        "        run_dashboard(dashboard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s6vYwgw90N15",
        "outputId": "dcf520f6-1085-442c-d674-dd4759a4e5c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and processing data...\n",
            "Running model pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in model performance analysis: name 'accuracy_score' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing analytics suite...\n",
            "Generating insights...\n",
            "\n",
            "=== INSIGHTS SUMMARY ===\n",
            "\n",
            "Customer Segments:\n",
            "         monthly_volume  risk_score  churned\n",
            "Segment                                     \n",
            "0                 24.39       25.37     0.20\n",
            "1                 77.97       75.53     0.20\n",
            "2                 25.33       74.56     0.19\n",
            "3                 73.01       28.28     0.15\n",
            "\n",
            "Risk Profiles:\n",
            "High Risk Clients: 250\n",
            "\n",
            "Recommendations:\n",
            "- High Risk Alert: Immediate review required (250 clients)\n",
            "- Growth Opportunity: Develop growth strategy (250 clients)\n",
            "\n",
            "Summary Statistics:\n",
            "Total Customers: 1000\n",
            "Average Volume: £49.23M\n",
            "Churn Rate: 18.80%\n",
            "\n",
            "Creating dashboard...\n",
            "Launching dashboard...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "html.Div(id='kpi-total-clients'),\n",
        "html.Div(id='kpi-avg-volume'),\n",
        "html.Div(id='kpi-churn-rate'),\n",
        "html.Div(id='kpi-risk-score'),\n",
        "dcc.Graph(id='volume-risk-scatter'),\n",
        "dcc.Graph(id='industry-distribution'),\n",
        "dcc.Graph(id='risk-distribution'),\n",
        "dcc.Graph(id='churn-analysis'),"
      ],
      "metadata": {
        "id": "6h828daYs_b6",
        "outputId": "ccf22b45-d964-4829-e566-058f0f9237d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Graph(id='churn-analysis'),)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComprehensiveDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__, external_stylesheets=[dbc.themes.FLATLY])\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Header\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    html.H1(\"FX Sales Analytics Dashboard\",\n",
        "                           className=\"text-center mb-4\")\n",
        "                ])\n",
        "            ]),\n",
        "\n",
        "            # Filters\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    html.Label(\"Select Industry\"),\n",
        "                    dcc.Dropdown(\n",
        "                        id='industry-filter',\n",
        "                        options=[\n",
        "                            {'label': str(x), 'value': str(x)}\n",
        "                            for x in self.analytics_suite.data['industry'].unique()\n",
        "                        ],\n",
        "                        value=None\n",
        "                    )\n",
        "                ], width=4),\n",
        "                dbc.Col([\n",
        "                    html.Label(\"Risk Level\"),\n",
        "                    dcc.RangeSlider(\n",
        "                        id='risk-slider',\n",
        "                        min=0,\n",
        "                        max=100,\n",
        "                        step=5,\n",
        "                        marks={i: str(i) for i in range(0, 101, 20)},\n",
        "                        value=[0, 100]\n",
        "                    )\n",
        "                ], width=8)\n",
        "            ]),\n",
        "\n",
        "            # KPI Cards\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Total Clients\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-total-clients\", children=\"0\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Average Volume\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-avg-volume\", children=\"0\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Churn Rate\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-churn-rate\", children=\"0%\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardBody([\n",
        "                            html.H4(\"Risk Score\", className=\"card-title\"),\n",
        "                            html.H2(id=\"kpi-risk-score\", children=\"0\")\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=3)\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # Main Charts\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(\n",
        "                        id='volume-risk-scatter',\n",
        "                        figure={}\n",
        "                    )\n",
        "                ], width=6),\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(\n",
        "                        id='industry-distribution',\n",
        "                        figure={}\n",
        "                    )\n",
        "                ], width=6)\n",
        "            ], className=\"mb-4\"),\n",
        "\n",
        "            # Additional Charts\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(\n",
        "                        id='risk-distribution',\n",
        "                        figure={}\n",
        "                    )\n",
        "                ], width=6),\n",
        "                dbc.Col([\n",
        "                    dcc.Graph(\n",
        "                        id='churn-analysis',\n",
        "                        figure={}\n",
        "                    )\n",
        "                ], width=6)\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        @self.app.callback(\n",
        "            [Output('kpi-total-clients', 'children'),\n",
        "             Output('kpi-avg-volume', 'children'),\n",
        "             Output('kpi-churn-rate', 'children'),\n",
        "             Output('kpi-risk-score', 'children'),\n",
        "             Output('volume-risk-scatter', 'figure'),\n",
        "             Output('industry-distribution', 'figure'),\n",
        "             Output('risk-distribution', 'figure'),\n",
        "             Output('churn-analysis', 'figure')],\n",
        "            [Input('industry-filter', 'value'),\n",
        "             Input('risk-slider', 'value')]\n",
        "        )\n",
        "        def update_dashboard(selected_industry, risk_range):\n",
        "            try:\n",
        "                df = self.analytics_suite.data.copy()\n",
        "                if selected_industry:\n",
        "                    df = df[df['industry'].astype(str) == selected_industry]\n",
        "                if risk_range:\n",
        "                    df = df[\n",
        "                        (df['risk_score'] >= risk_range[0]) &\n",
        "                        (df['risk_score'] <= risk_range[1])\n",
        "                    ]\n",
        "\n",
        "                # Calculate KPIs\n",
        "                kpis = self.calculate_kpis(df)\n",
        "\n",
        "                # Create figures\n",
        "                scatter_fig = self.create_scatter_plot(df)\n",
        "                industry_fig = self.create_industry_distribution(df)\n",
        "                risk_fig = self.create_risk_distribution(df)\n",
        "                churn_fig = self.create_churn_analysis(df)\n",
        "\n",
        "                return (\n",
        "                    f\"{kpis['total_clients']:,}\",\n",
        "                    f\"£{kpis['avg_volume']:.1f}M\",\n",
        "                    f\"{kpis['churn_rate']:.1%}\",\n",
        "                    f\"{kpis['risk_score']:.1f}\",\n",
        "                    scatter_fig,\n",
        "                    industry_fig,\n",
        "                    risk_fig,\n",
        "                    churn_fig\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"Callback error: {str(e)}\")\n",
        "                return \"0\", \"£0M\", \"0%\", \"0\", {}, {}, {}, {}\n",
        "\n",
        "    def run(self):\n",
        "        self.app.run_server(debug=True)"
      ],
      "metadata": {
        "id": "DKCvibrB0Ut1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analytics_suite, insights, dashboard = run_complete_analysis()\n",
        "\n",
        "if dashboard is not None:\n",
        "    dashboard.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "XQeT32qB0XjU",
        "outputId": "eefccf71-ce33-47f7-e148-1a33c3f2c282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-0b9047cbd734>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalytics_suite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minsights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdashboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_complete_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdashboard\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdashboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.FLATLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.error_status = {'last_error': None}\n",
        "        self.cache = {}\n",
        "        self.initialize_cache()\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def initialize_cache(self):\n",
        "        \"\"\"Initialize cache with computed values\"\"\"\n",
        "        try:\n",
        "            df = self.analytics_suite.data\n",
        "            self.cache.update({\n",
        "                'total_volume': df['monthly_volume'].sum(),\n",
        "                'avg_risk': df['risk_score'].mean(),\n",
        "                'industry_counts': df['industry'].value_counts().to_dict(),\n",
        "                'risk_segments': self.calculate_risk_segments(df)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Cache initialization failed\", e)\n",
        "\n",
        "    def log_error(self, context, error):\n",
        "        \"\"\"Enhanced error logging\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        error_msg = f\"{timestamp} - {context}: {str(error)}\"\n",
        "        print(error_msg)  # For immediate feedback\n",
        "        self.error_status['last_error'] = error_msg\n",
        "\n",
        "    def calculate_risk_segments(self, df):\n",
        "        \"\"\"Calculate risk segments\"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                'high_risk': len(df[df['risk_score'] >= 75]),\n",
        "                'medium_risk': len(df[(df['risk_score'] >= 25) & (df['risk_score'] < 75)]),\n",
        "                'low_risk': len(df[df['risk_score'] < 25])\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Risk segment calculation failed\", e)\n",
        "            return {'high_risk': 0, 'medium_risk': 0, 'low_risk': 0}\n",
        "\n",
        "    def setup_layout(self):\n",
        "        \"\"\"Enhanced dashboard layout\"\"\"\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Navigation Bar\n",
        "            dbc.Navbar(\n",
        "                dbc.Container([\n",
        "                    dbc.NavbarBrand(\"FX Sales Analytics\", className=\"ms-2\"),\n",
        "                    dbc.NavItem(dbc.NavLink(\"Refresh Data\", href=\"#\", id=\"refresh-data\")),\n",
        "                    dbc.NavItem(dbc.NavLink(\"Export Report\", href=\"#\", id=\"export-report\")),\n",
        "                    dbc.NavItem(\n",
        "                        dbc.Button(\"Error Log\", id=\"error-log-button\", color=\"danger\",\n",
        "                                 className=\"ms-2\", style={'display': 'none'})\n",
        "                    )\n",
        "                ]),\n",
        "                color=\"dark\",\n",
        "                dark=True,\n",
        "            ),\n",
        "\n",
        "            # Main Content\n",
        "            dbc.Container([\n",
        "                # Filters and Controls\n",
        "                dbc.Row([\n",
        "                    dbc.Col([\n",
        "                        html.Div([\n",
        "                            html.H4(\"Filters\", className=\"mb-3\"),\n",
        "                            dbc.Card([\n",
        "                                dbc.CardBody([\n",
        "                                    # Industry Filter\n",
        "                                    html.Label(\"Industry\"),\n",
        "                                    dcc.Dropdown(\n",
        "                                        id='industry-filter',\n",
        "                                        options=[\n",
        "                                            {'label': str(x), 'value': str(x)}\n",
        "                                            for x in self.analytics_suite.data['industry'].unique()\n",
        "                                        ],\n",
        "                                        multi=True,\n",
        "                                        placeholder=\"Select Industries\"\n",
        "                                    ),\n",
        "\n",
        "                                    # Risk Range Filter\n",
        "                                    html.Label(\"Risk Score Range\", className=\"mt-3\"),\n",
        "                                    dcc.RangeSlider(\n",
        "                                        id='risk-slider',\n",
        "                                        min=0,\n",
        "                                        max=100,\n",
        "                                        step=5,\n",
        "                                        marks={i: str(i) for i in range(0, 101, 20)},\n",
        "                                        value=[0, 100]\n",
        "                                    ),\n",
        "\n",
        "                                    # Volume Filter\n",
        "                                    html.Label(\"Monthly Volume (£M)\", className=\"mt-3\"),\n",
        "                                    dcc.RangeSlider(\n",
        "                                        id='volume-slider',\n",
        "                                        min=0,\n",
        "                                        max=self.analytics_suite.data['monthly_volume'].max(),\n",
        "                                        step=10,\n",
        "                                        value=[0, int(self.analytics_suite.data['monthly_volume'].max())]\n",
        "                                    ),\n",
        "\n",
        "                                    # Additional Controls\n",
        "                                    html.Div([\n",
        "                                        dbc.Button(\n",
        "                                            \"Reset Filters\",\n",
        "                                            id=\"reset-filters\",\n",
        "                                            color=\"secondary\",\n",
        "                                            className=\"mt-3\"\n",
        "                                        ),\n",
        "                                        dbc.Button(\n",
        "                                            \"Apply Filters\",\n",
        "                                            id=\"apply-filters\",\n",
        "                                            color=\"primary\",\n",
        "                                            className=\"mt-3 ms-2\"\n",
        "                                        )\n",
        "                                    ])\n",
        "                                ])\n",
        "                            ])\n",
        "                        ])\n",
        "                    ], width=3),\n",
        "\n",
        "                    # Main Content Area\n",
        "                    dbc.Col([\n",
        "                        # KPI Cards\n",
        "                        dbc.Row([\n",
        "                            dbc.Col(dbc.Card([\n",
        "                                dbc.CardBody([\n",
        "                                    html.H4(\"Total Clients\"),\n",
        "                                    html.H2(id=\"kpi-total-clients\"),\n",
        "                                    dbc.Progress(id=\"clients-progress\", value=0)\n",
        "                                ])\n",
        "                            ]), width=3),\n",
        "                            dbc.Col(dbc.Card([\n",
        "                                dbc.CardBody([\n",
        "                                    html.H4(\"Average Volume\"),\n",
        "                                    html.H2(id=\"kpi-avg-volume\"),\n",
        "                                    dbc.Progress(id=\"volume-progress\", value=0)\n",
        "                                ])\n",
        "                            ]), width=3),\n",
        "                            dbc.Col(dbc.Card([\n",
        "                                dbc.CardBody([\n",
        "                                    html.H4(\"Risk Score\"),\n",
        "                                    html.H2(id=\"kpi-risk-score\"),\n",
        "                                    dbc.Progress(id=\"risk-progress\", value=0)\n",
        "                                ])\n",
        "                            ]), width=3),\n",
        "                            dbc.Col(dbc.Card([\n",
        "                                dbc.CardBody([\n",
        "                                    html.H4(\"Churn Rate\"),\n",
        "                                    html.H2(id=\"kpi-churn-rate\"),\n",
        "                                    dbc.Progress(id=\"churn-progress\", value=0)\n",
        "                                ])\n",
        "                            ]), width=3),\n",
        "                        ], className=\"mb-4\"),\n",
        "\n",
        "                        # Main Charts\n",
        "                        dbc.Tabs([\n",
        "                            dbc.Tab([\n",
        "                                dcc.Graph(id='volume-risk-scatter')\n",
        "                            ], label=\"Risk Analysis\"),\n",
        "\n",
        "                            dbc.Tab([\n",
        "                                dcc.Graph(id='industry-distribution')\n",
        "                            ], label=\"Industry Analysis\"),\n",
        "\n",
        "                            dbc.Tab([\n",
        "                                dcc.Graph(id='time-series-analysis')\n",
        "                            ], label=\"Time Series\"),\n",
        "\n",
        "                            dbc.Tab([\n",
        "                                dcc.Graph(id='customer-segments')\n",
        "                            ], label=\"Segmentation\")\n",
        "                        ])\n",
        "                    ], width=9)\n",
        "                ])\n",
        "            ], fluid=True)\n",
        "        ])"
      ],
      "metadata": {
        "id": "c_T8VcVj0ZEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def setup_callbacks(self):\n",
        "        \"\"\"Setup all dashboard callbacks\"\"\"\n",
        "        self.setup_filter_callbacks()\n",
        "        self.setup_chart_callbacks()\n",
        "        self.setup_error_callbacks()\n",
        "        self.setup_export_callbacks()\n",
        "\n",
        "    def setup_filter_callbacks(self):\n",
        "        @self.app.callback(\n",
        "            [Output('kpi-total-clients', 'children'),\n",
        "             Output('kpi-avg-volume', 'children'),\n",
        "             Output('kpi-risk-score', 'children'),\n",
        "             Output('kpi-churn-rate', 'children'),\n",
        "             Output('clients-progress', 'value'),\n",
        "             Output('volume-progress', 'value'),\n",
        "             Output('risk-progress', 'value'),\n",
        "             Output('churn-progress', 'value')],\n",
        "            [Input('industry-filter', 'value'),\n",
        "             Input('risk-slider', 'value'),\n",
        "             Input('volume-slider', 'value'),\n",
        "             Input('apply-filters', 'n_clicks')],\n",
        "            [State('industry-filter', 'value')]\n",
        "        )\n",
        "        def update_kpis(industries, risk_range, volume_range, n_clicks, current_industries):\n",
        "            try:\n",
        "                # Get filtered dataframe\n",
        "                df = self.get_filtered_data(industries, risk_range, volume_range)\n",
        "                total_clients = len(df)\n",
        "                avg_volume = df['monthly_volume'].mean()\n",
        "                risk_score = df['risk_score'].mean()\n",
        "                churn_rate = df['churned'].mean()\n",
        "\n",
        "                # Calculate progress values\n",
        "                clients_progress = (total_clients / len(self.analytics_suite.data)) * 100\n",
        "                volume_progress = (avg_volume / self.cache['total_volume']) * 100\n",
        "                risk_progress = risk_score\n",
        "                churn_progress = churn_rate * 100\n",
        "\n",
        "                return (\n",
        "                    f\"{total_clients:,}\",\n",
        "                    f\"£{avg_volume:.1f}M\",\n",
        "                    f\"{risk_score:.1f}\",\n",
        "                    f\"{churn_rate:.1%}\",\n",
        "                    clients_progress,\n",
        "                    volume_progress,\n",
        "                    risk_progress,\n",
        "                    churn_progress\n",
        "                )\n",
        "            except Exception as e:\n",
        "                self.log_error(\"KPI update failed\", e)\n",
        "                return \"0\", \"£0M\", \"0\", \"0%\", 0, 0, 0, 0\n",
        "\n",
        "    def setup_chart_callbacks(self):\n",
        "        @self.app.callback(\n",
        "            [Output('volume-risk-scatter', 'figure'),\n",
        "             Output('industry-distribution', 'figure'),\n",
        "             Output('time-series-analysis', 'figure'),\n",
        "             Output('customer-segments', 'figure')],\n",
        "            [Input('industry-filter', 'value'),\n",
        "             Input('risk-slider', 'value'),\n",
        "             Input('volume-slider', 'value')]\n",
        "        )\n",
        "        def update_charts(industries, risk_range, volume_range):\n",
        "            try:\n",
        "                df = self.get_filtered_data(industries, risk_range, volume_range)\n",
        "\n",
        "                return (\n",
        "                    self.create_risk_scatter(df),\n",
        "                    self.create_industry_distribution(df),\n",
        "                    self.create_time_series(df),\n",
        "                    self.create_customer_segments(df)\n",
        "                )\n",
        "            except Exception as e:\n",
        "                self.log_error(\"Chart update failed\", e)\n",
        "                return {}, {}, {}, {}\n",
        "\n",
        "    def create_risk_scatter(self, df):\n",
        "        \"\"\"Create advanced risk scatter plot\"\"\"\n",
        "        fig = px.scatter(\n",
        "            df,\n",
        "            x='monthly_volume',\n",
        "            y='risk_score',\n",
        "            color='industry',\n",
        "            size='monthly_volume',\n",
        "            hover_data=[\n",
        "                'churned',\n",
        "                'platform_usage_hours',\n",
        "                'credit_score'\n",
        "            ],\n",
        "            title='Risk vs Volume Analysis',\n",
        "            template='plotly_dark'\n",
        "        )\n",
        "\n",
        "        # Add risk zones\n",
        "        fig.add_hrect(\n",
        "            y0=75, y1=100,\n",
        "            fillcolor=\"red\", opacity=0.1,\n",
        "            layer=\"below\", line_width=0,\n",
        "            annotation_text=\"High Risk Zone\"\n",
        "        )\n",
        "\n",
        "        fig.add_hrect(\n",
        "            y0=25, y1=75,\n",
        "            fillcolor=\"yellow\", opacity=0.1,\n",
        "            layer=\"below\", line_width=0,\n",
        "            annotation_text=\"Medium Risk Zone\"\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def create_industry_distribution(self, df):\n",
        "        \"\"\"Create industry distribution analysis\"\"\"\n",
        "        # Create subplots\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=(\n",
        "                'Industry Distribution',\n",
        "                'Average Volume by Industry',\n",
        "                'Risk Distribution by Industry',\n",
        "                'Churn Rate by Industry'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Industry Distribution\n",
        "        industry_counts = df['industry'].value_counts()\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=industry_counts.index, y=industry_counts.values),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Average Volume\n",
        "        volume_by_industry = df.groupby('industry')['monthly_volume'].mean()\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=volume_by_industry.index, y=volume_by_industry.values),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        # Risk Distribution\n",
        "        risk_by_industry = df.groupby('industry')['risk_score'].mean()\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=risk_by_industry.index, y=risk_by_industry.values),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # Churn Rate\n",
        "        churn_by_industry = df.groupby('industry')['churned'].mean()\n",
        "        fig.add_trace(\n",
        "            go.Bar(x=churn_by_industry.index, y=churn_by_industry.values),\n",
        "            row=2, col=2\n",
        "        )\n",
        "\n",
        "        fig.update_layout(height=800, showlegend=False)\n",
        "        return fig\n",
        "\n",
        "    def create_time_series(self, df):\n",
        "        \"\"\"Create time series analysis\"\"\"\n",
        "        # Group by date and calculate metrics\n",
        "        daily_metrics = df.groupby('date').agg({\n",
        "            'monthly_volume': 'sum',\n",
        "            'risk_score': 'mean',\n",
        "            'churned': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        fig = make_subplots(rows=3, cols=1, shared_xaxes=True)\n",
        "\n",
        "        # Volume Trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=daily_metrics['date'],\n",
        "                y=daily_metrics['monthly_volume'],\n",
        "                name='Volume'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # Risk Trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=daily_metrics['date'],\n",
        "                y=daily_metrics['risk_score'],\n",
        "                name='Risk'\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # Churn Trend\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=daily_metrics['date'],\n",
        "                y=daily_metrics['churned'],\n",
        "                name='Churn'\n",
        "            ),\n",
        "            row=3, col=1\n",
        "        )\n",
        "\n",
        "        fig.update_layout(height=800)\n",
        "        return fig\n",
        "\n",
        "    def create_customer_segments(self, df):\n",
        "        \"\"\"Create customer segmentation analysis\"\"\"\n",
        "        # Perform clustering\n",
        "        features_for_clustering = ['monthly_volume', 'risk_score', 'platform_usage_hours']\n",
        "        X = StandardScaler().fit_transform(df[features_for_clustering])\n",
        "\n",
        "        kmeans = KMeans(n_clusters=4, random_state=42)\n",
        "        df['Segment'] = kmeans.fit_predict(X)\n",
        "\n",
        "        fig = px.scatter_3d(\n",
        "            df,\n",
        "            x='monthly_volume',\n",
        "            y='risk_score',\n",
        "            z='platform_usage_hours',\n",
        "            color='Segment',\n",
        "            hover_data=['industry', 'churned'],\n",
        "            title='Customer Segments'\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    def get_filtered_data(self, industries, risk_range, volume_range):\n",
        "        \"\"\"Get filtered dataframe based on selections\"\"\"\n",
        "        df = self.analytics_suite.data.copy()\n",
        "\n",
        "        if industries:\n",
        "            if isinstance(industries, list):\n",
        "                df = df[df['industry'].isin(industries)]\n",
        "            else:\n",
        "                df = df[df['industry'] == industries]\n",
        "\n",
        "        if risk_range:\n",
        "            df = df[\n",
        "                (df['risk_score'] >= risk_range[0]) &\n",
        "                (df['risk_score'] <= risk_range[1])\n",
        "            ]\n",
        "\n",
        "        if volume_range:\n",
        "            df = df[\n",
        "                (df['monthly_volume'] >= volume_range[0]) &\n",
        "                (df['monthly_volume'] <= volume_range[1])\n",
        "            ]\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "NiCm7zwq2B14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedDashboard:\n",
        "    def add_performance_optimizations(self):\n",
        "        \"\"\"Add performance optimizations to the dashboard\"\"\"\n",
        "\n",
        "        # Data caching system\n",
        "        self.cache = {\n",
        "            'data': {},\n",
        "            'computations': {},\n",
        "            'last_update': None,\n",
        "            'update_frequency': 300  # 5 minutes in seconds\n",
        "        }\n",
        "\n",
        "        # Background task handler\n",
        "        self.background_tasks = {\n",
        "            'running': False,\n",
        "            'last_error': None,\n",
        "            'status': 'idle'\n",
        "        }\n",
        "\n",
        "    def setup_performance_monitoring(self):\n",
        "        \"\"\"Setup performance monitoring\"\"\"\n",
        "        self.performance_metrics = {\n",
        "            'response_times': [],\n",
        "            'memory_usage': [],\n",
        "            'cache_hits': 0,\n",
        "            'cache_misses': 0\n",
        "        }\n",
        "\n",
        "    @property\n",
        "    def needs_update(self):\n",
        "        \"\"\"Check if cache needs update\"\"\"\n",
        "        if not self.cache['last_update']:\n",
        "            return True\n",
        "        return (datetime.now() - self.cache['last_update']).seconds > self.cache['update_frequency']\n",
        "\n",
        "    def update_cache(self):\n",
        "        \"\"\"Update cache with latest computations\"\"\"\n",
        "        try:\n",
        "            df = self.analytics_suite.data\n",
        "\n",
        "            # Pre-compute common aggregations\n",
        "            self.cache['data'] = {\n",
        "                'industry_metrics': self.compute_industry_metrics(df),\n",
        "                'risk_metrics': self.compute_risk_metrics(df),\n",
        "                'time_series': self.compute_time_series_metrics(df),\n",
        "                'customer_segments': self.compute_customer_segments(df)\n",
        "            }\n",
        "\n",
        "            self.cache['last_update'] = datetime.now()\n",
        "            logger.info(\"Cache updated successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Cache update failed: {str(e)}\")\n",
        "            self.background_tasks['last_error'] = str(e)\n",
        "\n",
        "    def add_advanced_features(self):\n",
        "        \"\"\"Add advanced features to the dashboard\"\"\"\n",
        "\n",
        "        # Add predictive analytics\n",
        "        self.setup_predictive_analytics()\n",
        "\n",
        "        # Add anomaly detection\n",
        "        self.setup_anomaly_detection()\n",
        "\n",
        "        # Add advanced filtering\n",
        "        self.setup_advanced_filtering()\n",
        "\n",
        "        # Add export capabilities\n",
        "        self.setup_export_capabilities()\n",
        "\n",
        "    def setup_predictive_analytics(self):\n",
        "        \"\"\"Setup predictive analytics features\"\"\"\n",
        "        @self.app.callback(\n",
        "            Output('prediction-results', 'children'),\n",
        "            [Input('predict-button', 'n_clicks')],\n",
        "            [State('industry-filter', 'value')]\n",
        "        )\n",
        "        def update_predictions(n_clicks, industry):\n",
        "            if not n_clicks:\n",
        "                return []\n",
        "\n",
        "            try:\n",
        "                df = self.get_filtered_data([industry] if industry else None, None, None)\n",
        "                predictions = self.generate_predictions(df)\n",
        "                return self.create_prediction_cards(predictions)\n",
        "            except Exception as e:\n",
        "                self.log_error(\"Prediction update failed\", e)\n",
        "                return []\n",
        "\n",
        "    def generate_predictions(self, df):\n",
        "        \"\"\"Generate predictions for clients\"\"\"\n",
        "        try:\n",
        "            # Churn prediction\n",
        "            churn_predictions = self.analytics_suite.pipeline.best_model.predict_proba(\n",
        "                self.analytics_suite.pipeline.X_test\n",
        "            )[:, 1]\n",
        "\n",
        "            # Volume prediction using time series\n",
        "            volume_predictions = self.predict_volume(df)\n",
        "\n",
        "            # Risk trend prediction\n",
        "            risk_predictions = self.predict_risk_trends(df)\n",
        "\n",
        "            return {\n",
        "                'churn_predictions': churn_predictions,\n",
        "                'volume_predictions': volume_predictions,\n",
        "                'risk_predictions': risk_predictions\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Prediction generation failed\", e)\n",
        "            return None\n",
        "\n",
        "    def setup_anomaly_detection(self):\n",
        "        \"\"\"Setup anomaly detection system\"\"\"\n",
        "        @self.app.callback(\n",
        "            Output('anomaly-indicators', 'children'),\n",
        "            [Input('check-anomalies-button', 'n_clicks')]\n",
        "        )\n",
        "        def update_anomalies(n_clicks):\n",
        "            if not n_clicks:\n",
        "                return []\n",
        "\n",
        "            try:\n",
        "                anomalies = self.detect_anomalies()\n",
        "                return self.create_anomaly_alerts(anomalies)\n",
        "            except Exception as e:\n",
        "                self.log_error(\"Anomaly detection failed\", e)\n",
        "                return []\n",
        "\n",
        "    def detect_anomalies(self):\n",
        "        \"\"\"Detect anomalies in the data\"\"\"\n",
        "        df = self.analytics_suite.data\n",
        "        anomalies = {\n",
        "            'volume_anomalies': self.detect_volume_anomalies(df),\n",
        "            'risk_anomalies': self.detect_risk_anomalies(df),\n",
        "            'behavior_anomalies': self.detect_behavior_anomalies(df)\n",
        "        }\n",
        "        return anomalies\n",
        "\n",
        "    def setup_advanced_filtering(self):\n",
        "        \"\"\"Setup advanced filtering capabilities\"\"\"\n",
        "        @self.app.callback(\n",
        "            Output('filtered-data-table', 'data'),\n",
        "            [Input('advanced-filter-button', 'n_clicks')],\n",
        "            [State('filter-conditions', 'value')]\n",
        "        )\n",
        "        def apply_advanced_filters(n_clicks, conditions):\n",
        "            if not n_clicks:\n",
        "                return []\n",
        "\n",
        "            try:\n",
        "                filtered_data = self.apply_complex_filters(conditions)\n",
        "                return filtered_data.to_dict('records')\n",
        "            except Exception as e:\n",
        "                self.log_error(\"Advanced filtering failed\", e)\n",
        "                return []\n",
        "\n",
        "    def setup_export_capabilities(self):\n",
        "        \"\"\"Setup data export capabilities\"\"\"\n",
        "        @self.app.callback(\n",
        "            Output('download-data', 'data'),\n",
        "            [Input('export-button', 'n_clicks')],\n",
        "            [State('export-format', 'value')]\n",
        "        )\n",
        "        def export_data(n_clicks, export_format):\n",
        "            if not n_clicks:\n",
        "                return None\n",
        "\n",
        "            try:\n",
        "                return self.prepare_export_data(export_format)\n",
        "            except Exception as e:\n",
        "                self.log_error(\"Data export failed\", e)\n",
        "                return None\n",
        "\n",
        "    def prepare_export_data(self, export_format):\n",
        "        \"\"\"Prepare data for export\"\"\"\n",
        "        df = self.analytics_suite.data\n",
        "\n",
        "        if export_format == 'csv':\n",
        "            return dict(content=df.to_csv(index=False), filename=\"fx_sales_data.csv\")\n",
        "        elif export_format == 'excel':\n",
        "            return dict(content=df.to_excel(index=False), filename=\"fx_sales_data.xlsx\")\n",
        "        elif export_format == 'json':\n",
        "            return dict(content=df.to_json(orient='records'), filename=\"fx_sales_data.json\")\n",
        "\n",
        "    def add_real_time_updates(self):\n",
        "        \"\"\"Add real-time update capabilities\"\"\"\n",
        "        @self.app.callback(\n",
        "            Output('last-update-time', 'children'),\n",
        "            [Input('interval-component', 'n_intervals')]\n",
        "        )\n",
        "        def update_data(n):\n",
        "            if self.needs_update:\n",
        "                self.update_cache()\n",
        "            return f\"Last updated: {self.cache['last_update'].strftime('%H:%M:%S')}\"\n",
        "\n",
        "    def optimize_layout(self):\n",
        "        \"\"\"Optimize dashboard layout\"\"\"\n",
        "        self.app.layout = html.Div([\n",
        "            dcc.Store(id='session-store'),\n",
        "            dcc.Store(id='local-store', storage_type='local'),\n",
        "            dcc.Interval(\n",
        "                id='interval-component',\n",
        "                interval=5*60*1000,  # 5 minutes\n",
        "                n_intervals=0\n",
        "            ),\n",
        "            self.create_layout()\n",
        "        ])\n",
        "\n",
        "    def setup_error_handling(self):\n",
        "        \"\"\"Setup enhanced error handling\"\"\"\n",
        "        @self.app.callback(\n",
        "            Output('error-log', 'children'),\n",
        "            [Input('error-check-interval', 'n_intervals')]\n",
        "        )\n",
        "        def update_error_log(n):\n",
        "            if self.background_tasks['last_error']:\n",
        "                return html.Div([\n",
        "                    html.H4(\"Error Log\"),\n",
        "                    html.P(self.background_tasks['last_error'])\n",
        "                ])\n",
        "            return []"
      ],
      "metadata": {
        "id": "DaKmj4va2CZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedDashboard:\n",
        "    def __init__(self, analytics_suite=None):  # Add initialization parameter\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.FLATLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.error_status = {'last_error': None}\n",
        "        self.cache = {}\n",
        "        self.initialize_cache()\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def initialize_cache(self):\n",
        "        \"\"\"Initialize cache with computed values\"\"\"\n",
        "        try:\n",
        "            if self.analytics_suite is not None:\n",
        "                df = self.analytics_suite.data\n",
        "                self.cache.update({\n",
        "                    'total_volume': df['monthly_volume'].sum(),\n",
        "                    'avg_risk': df['risk_score'].mean(),\n",
        "                    'industry_counts': df['industry'].value_counts().to_dict(),\n",
        "                    'risk_segments': self.calculate_risk_segments(df)\n",
        "                })\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Cache initialization failed\", e)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the dashboard\"\"\"\n",
        "        try:\n",
        "            self.app.run_server(debug=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error running dashboard: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    # Rest of the EnhancedDashboard class implementation remains the same...\n",
        "\n",
        "def launch_dashboard(analytics_suite):\n",
        "    \"\"\"Launch the dashboard with error handling\"\"\"\n",
        "    try:\n",
        "        print(\"\\nInitializing dashboard...\")\n",
        "        dashboard = EnhancedDashboard(analytics_suite=analytics_suite)\n",
        "\n",
        "        print(\"\\nDashboard is ready!\")\n",
        "        print(\"Access the dashboard at: http://127.0.0.1:8050\")\n",
        "        print(\"\\nPress Ctrl+C to stop the dashboard\")\n",
        "\n",
        "        dashboard.run()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error launching dashboard: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run analysis\n",
        "        print(\"Running analysis...\")\n",
        "        analytics_suite, insights = run_complete_analysis()\n",
        "\n",
        "        if analytics_suite is not None:\n",
        "            # Launch dashboard\n",
        "            print(\"\\nLaunching dashboard...\")\n",
        "            launch_dashboard(analytics_suite)\n",
        "        else:\n",
        "            print(\"Analysis failed, cannot launch dashboard.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UssZ7Aja37Lo",
        "outputId": "1316d783-d063-4e1f-f0a5-5b1c6fc54256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running analysis...\n",
            "Generating and processing data...\n",
            "Running model pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in model performance analysis: name 'accuracy_score' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing analytics suite...\n",
            "Generating insights...\n",
            "\n",
            "=== INSIGHTS SUMMARY ===\n",
            "\n",
            "Customer Segments:\n",
            "         monthly_volume  risk_score  churned\n",
            "Segment                                     \n",
            "0                 24.39       25.37     0.20\n",
            "1                 77.97       75.53     0.20\n",
            "2                 25.33       74.56     0.19\n",
            "3                 73.01       28.28     0.15\n",
            "\n",
            "Risk Profiles:\n",
            "High Risk Clients: 250\n",
            "\n",
            "Recommendations:\n",
            "- High Risk Alert: Immediate review required (250 clients)\n",
            "- Growth Opportunity: Develop growth strategy (250 clients)\n",
            "\n",
            "Summary Statistics:\n",
            "Total Customers: 1000\n",
            "Average Volume: £49.23M\n",
            "Churn Rate: 18.80%\n",
            "\n",
            "Creating dashboard...\n",
            "Error in main execution: too many values to unpack (expected 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-104-7fdecb465640>\", line 58, in <cell line: 0>\n",
            "    analytics_suite, insights = run_complete_analysis()\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: too many values to unpack (expected 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedDashboard:\n",
        "    def __init__(self, analytics_suite=None):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.FLATLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.error_status = {'last_error': None}\n",
        "        self.cache = {}\n",
        "        self.setup_logging()\n",
        "        self.initialize_cache()\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Setup logging for the dashboard\"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        if not self.logger.handlers:\n",
        "            handler = logging.StreamHandler()\n",
        "            formatter = logging.Formatter(\n",
        "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "            )\n",
        "            handler.setFormatter(formatter)\n",
        "            self.logger.addHandler(handler)\n",
        "            self.logger.setLevel(logging.INFO)\n",
        "\n",
        "    def log_error(self, message, error):\n",
        "        \"\"\"Log error messages\"\"\"\n",
        "        error_msg = f\"{message}: {str(error)}\"\n",
        "        self.logger.error(error_msg)\n",
        "        self.error_status['last_error'] = error_msg\n",
        "\n",
        "    def calculate_risk_segments(self, df):\n",
        "        \"\"\"Calculate risk segments\"\"\"\n",
        "        try:\n",
        "            return {\n",
        "                'high_risk': len(df[df['risk_score'] >= 75]),\n",
        "                'medium_risk': len(df[(df['risk_score'] >= 25) & (df['risk_score'] < 75)]),\n",
        "                'low_risk': len(df[df['risk_score'] < 25])\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Risk segment calculation failed\", e)\n",
        "            return {'high_risk': 0, 'medium_risk': 0, 'low_risk': 0}\n",
        "\n",
        "    def initialize_cache(self):\n",
        "        \"\"\"Initialize cache with computed values\"\"\"\n",
        "        try:\n",
        "            if self.analytics_suite is not None:\n",
        "                df = self.analytics_suite.data\n",
        "                self.cache.update({\n",
        "                    'total_volume': df['monthly_volume'].sum(),\n",
        "                    'avg_risk': df['risk_score'].mean(),\n",
        "                    'industry_counts': df['industry'].value_counts().to_dict(),\n",
        "                    'risk_segments': self.calculate_risk_segments(df)\n",
        "                })\n",
        "                self.logger.info(\"Cache initialized successfully\")\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Cache initialization failed\", e)\n",
        "\n",
        "    def setup_layout(self):\n",
        "        \"\"\"Setup dashboard layout\"\"\"\n",
        "        try:\n",
        "            self.app.layout = dbc.Container([\n",
        "                # Header\n",
        "                dbc.Row([\n",
        "                    dbc.Col([\n",
        "                        html.H1(\"FX Sales Analytics Dashboard\",\n",
        "                               className=\"text-center mb-4\")\n",
        "                    ])\n",
        "                ]),\n",
        "\n",
        "                # Filters\n",
        "                dbc.Row([\n",
        "                    dbc.Col([\n",
        "                        html.Label(\"Select Industry\"),\n",
        "                        dcc.Dropdown(\n",
        "                            id='industry-filter',\n",
        "                            options=[\n",
        "                                {'label': str(x), 'value': str(x)}\n",
        "                                for x in self.analytics_suite.data['industry'].unique()\n",
        "                            ] if self.analytics_suite is not None else [],\n",
        "                            value=None\n",
        "                        )\n",
        "                    ], width=6)\n",
        "                ]),\n",
        "\n",
        "                # KPI Cards\n",
        "                dbc.Row([\n",
        "                    dbc.Col([\n",
        "                        dbc.Card([\n",
        "                            dbc.CardBody([\n",
        "                                html.H4(\"Total Clients\"),\n",
        "                                html.H2(id=\"kpi-total-clients\", children=\"0\")\n",
        "                            ])\n",
        "                        ])\n",
        "                    ], width=3),\n",
        "                    dbc.Col([\n",
        "                        dbc.Card([\n",
        "                            dbc.CardBody([\n",
        "                                html.H4(\"Average Volume\"),\n",
        "                                html.H2(id=\"kpi-avg-volume\", children=\"£0M\")\n",
        "                            ])\n",
        "                        ])\n",
        "                    ], width=3),\n",
        "                    dbc.Col([\n",
        "                        dbc.Card([\n",
        "                            dbc.CardBody([\n",
        "                                html.H4(\"Risk Score\"),\n",
        "                                html.H2(id=\"kpi-risk-score\", children=\"0\")\n",
        "                            ])\n",
        "                        ])\n",
        "                    ], width=3),\n",
        "                    dbc.Col([\n",
        "                        dbc.Card([\n",
        "                            dbc.CardBody([\n",
        "                                html.H4(\"Churn Rate\"),\n",
        "                                html.H2(id=\"kpi-churn-rate\", children=\"0%\")\n",
        "                            ])\n",
        "                        ])\n",
        "                    ], width=3)\n",
        "                ], className=\"mb-4\"),\n",
        "\n",
        "                # Main Chart\n",
        "                dbc.Row([\n",
        "                    dbc.Col([\n",
        "                        dcc.Graph(id='main-chart')\n",
        "                    ])\n",
        "                ])\n",
        "            ], fluid=True)\n",
        "\n",
        "            self.logger.info(\"Layout setup completed\")\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Layout setup failed\", e)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Setup dashboard callbacks\"\"\"\n",
        "        try:\n",
        "            @self.app.callback(\n",
        "                [Output('kpi-total-clients', 'children'),\n",
        "                 Output('kpi-avg-volume', 'children'),\n",
        "                 Output('kpi-risk-score', 'children'),\n",
        "                 Output('kpi-churn-rate', 'children'),\n",
        "                 Output('main-chart', 'figure')],\n",
        "                [Input('industry-filter', 'value')]\n",
        "            )\n",
        "            def update_dashboard(selected_industry):\n",
        "                try:\n",
        "                    df = self.analytics_suite.data\n",
        "                    if selected_industry:\n",
        "                        df = df[df['industry'].astype(str) == selected_industry]\n",
        "\n",
        "                    # Calculate KPIs\n",
        "                    total_clients = len(df)\n",
        "                    avg_volume = df['monthly_volume'].mean()\n",
        "                    risk_score = df['risk_score'].mean()\n",
        "                    churn_rate = df['churned'].mean()\n",
        "\n",
        "                    # Create main chart\n",
        "                    fig = px.scatter(\n",
        "                        df,\n",
        "                        x='monthly_volume',\n",
        "                        y='risk_score',\n",
        "                        color='industry',\n",
        "                        title='Volume vs Risk Analysis'\n",
        "                    )\n",
        "\n",
        "                    return (\n",
        "                        f\"{total_clients:,}\",\n",
        "                        f\"£{avg_volume:.1f}M\",\n",
        "                        f\"{risk_score:.1f}\",\n",
        "                        f\"{churn_rate:.1%}\",\n",
        "                        fig\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    self.log_error(\"Callback update failed\", e)\n",
        "                    return \"0\", \"£0M\", \"0\", \"0%\", {}\n",
        "\n",
        "            self.logger.info(\"Callbacks setup completed\")\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Callback setup failed\", e)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the dashboard\"\"\"\n",
        "        try:\n",
        "            self.logger.info(\"Starting dashboard server...\")\n",
        "            self.app.run_server(debug=True)\n",
        "        except Exception as e:\n",
        "            self.log_error(\"Dashboard server failed to start\", e)\n",
        "            raise\n",
        "\n",
        "def launch_dashboard(analytics_suite):\n",
        "    \"\"\"Launch the dashboard with error handling\"\"\"\n",
        "    try:\n",
        "        print(\"\\nInitializing dashboard...\")\n",
        "        dashboard = EnhancedDashboard(analytics_suite=analytics_suite)\n",
        "\n",
        "        print(\"\\nDashboard is ready!\")\n",
        "        print(\"Access the dashboard at: http://127.0.0.1:8050\")\n",
        "        print(\"\\nPress Ctrl+C to stop the dashboard\")\n",
        "\n",
        "        dashboard.run()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error launching dashboard: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Run analysis\n",
        "        print(\"Running analysis...\")\n",
        "        analytics_suite, insights = run_complete_analysis()\n",
        "\n",
        "        if analytics_suite is not None:\n",
        "            # Launch dashboard\n",
        "            print(\"\\nLaunching dashboard...\")\n",
        "            launch_dashboard(analytics_suite)\n",
        "        else:\n",
        "            print(\"Analysis failed, cannot launch dashboard.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in main execution: {str(e)}\")\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC6TEjvh7whE",
        "outputId": "d86906dd-2e71-4fed-f6a5-1fabc4d0ab4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running analysis...\n",
            "Generating and processing data...\n",
            "Running model pipeline...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Error in model performance analysis: name 'accuracy_score' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing analytics suite...\n",
            "Generating insights...\n",
            "\n",
            "=== INSIGHTS SUMMARY ===\n",
            "\n",
            "Customer Segments:\n",
            "         monthly_volume  risk_score  churned\n",
            "Segment                                     \n",
            "0                 24.39       25.37     0.20\n",
            "1                 77.97       75.53     0.20\n",
            "2                 25.33       74.56     0.19\n",
            "3                 73.01       28.28     0.15\n",
            "\n",
            "Risk Profiles:\n",
            "High Risk Clients: 250\n",
            "\n",
            "Recommendations:\n",
            "- High Risk Alert: Immediate review required (250 clients)\n",
            "- Growth Opportunity: Develop growth strategy (250 clients)\n",
            "\n",
            "Summary Statistics:\n",
            "Total Customers: 1000\n",
            "Average Volume: £49.23M\n",
            "Churn Rate: 18.80%\n",
            "\n",
            "Creating dashboard...\n",
            "Error in main execution: too many values to unpack (expected 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-105-39653b0ffc72>\", line 211, in <cell line: 0>\n",
            "    analytics_suite, insights = run_complete_analysis()\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "ValueError: too many values to unpack (expected 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite=None):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(\n",
        "            __name__,\n",
        "            external_stylesheets=[dbc.themes.FLATLY],\n",
        "            suppress_callback_exceptions=True\n",
        "        )\n",
        "\n",
        "        # Initialize components\n",
        "        self.setup_logging()\n",
        "        self.initialize_cache()\n",
        "        self.setup_ml_models()\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_logging(self):\n",
        "        \"\"\"Setup enhanced logging system\"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        handler = logging.StreamHandler()\n",
        "        formatter = logging.Formatter(\n",
        "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        handler.setFormatter(formatter)\n",
        "        self.logger.addHandler(handler)\n",
        "        self.logger.setLevel(logging.INFO)\n",
        "\n",
        "    def setup_layout(self):\n",
        "        \"\"\"Setup advanced dashboard layout\"\"\"\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Navigation Bar\n",
        "            self.create_navbar(),\n",
        "\n",
        "            # Main Content Area\n",
        "            dbc.Row([\n",
        "                # Sidebar\n",
        "                dbc.Col([\n",
        "                    self.create_sidebar()\n",
        "                ], width=2),\n",
        "\n",
        "                # Main Content\n",
        "                dbc.Col([\n",
        "                    dbc.Tabs([\n",
        "                        # Predictive Analytics Tab\n",
        "                        dbc.Tab([\n",
        "                            self.create_predictive_tab()\n",
        "                        ], label=\"Predictive Analytics\"),\n",
        "\n",
        "                        # Customer Segmentation Tab\n",
        "                        dbc.Tab([\n",
        "                            self.create_segmentation_tab()\n",
        "                        ], label=\"Customer Segmentation\"),\n",
        "\n",
        "                        # Risk Analysis Tab\n",
        "                        dbc.Tab([\n",
        "                            self.create_risk_tab()\n",
        "                        ], label=\"Risk Analysis\"),\n",
        "\n",
        "                        # Business Intelligence Tab\n",
        "                        dbc.Tab([\n",
        "                            self.create_bi_tab()\n",
        "                        ], label=\"Business Intelligence\"),\n",
        "\n",
        "                        # Operations Tab\n",
        "                        dbc.Tab([\n",
        "                            self.create_operations_tab()\n",
        "                        ], label=\"Operations\")\n",
        "                    ])\n",
        "                ], width=10)\n",
        "            ]),\n",
        "\n",
        "            # Footer\n",
        "            self.create_footer()\n",
        "\n",
        "        ], fluid=True)\n",
        "\n",
        "    def create_navbar(self):\n",
        "        \"\"\"Create navigation bar\"\"\"\n",
        "        return dbc.Navbar(\n",
        "            dbc.Container([\n",
        "                dbc.NavbarBrand(\"Advanced FX Analytics\", className=\"ms-2\"),\n",
        "                dbc.Nav([\n",
        "                    dbc.NavItem(dbc.NavLink(\"Dashboard\", href=\"#\")),\n",
        "                    dbc.NavItem(dbc.NavLink(\"Reports\", href=\"#\")),\n",
        "                    dbc.NavItem(dbc.NavLink(\"Settings\", href=\"#\")),\n",
        "                    dbc.NavItem(\n",
        "                        dbc.Button(\"Export\", color=\"success\", className=\"ms-2\")\n",
        "                    ),\n",
        "                    dbc.NavItem(\n",
        "                        dbc.Button(\"Alerts\", color=\"danger\", className=\"ms-2\")\n",
        "                    )\n",
        "                ]),\n",
        "                dbc.NavbarToggler(id=\"navbar-toggler\")\n",
        "            ]),\n",
        "            color=\"dark\",\n",
        "            dark=True\n",
        "        )\n",
        "\n",
        "    def create_sidebar(self):\n",
        "        \"\"\"Create sidebar with filters and controls\"\"\"\n",
        "        return html.Div([\n",
        "            html.H4(\"Filters\", className=\"mb-3\"),\n",
        "            html.Label(\"Time Period\"),\n",
        "            dcc.DatePickerRange(\n",
        "                id='date-range',\n",
        "                start_date=datetime.now() - timedelta(days=30),\n",
        "                end_date=datetime.now()\n",
        "            ),\n",
        "            html.Label(\"Industry\", className=\"mt-3\"),\n",
        "            dcc.Dropdown(\n",
        "                id='industry-filter',\n",
        "                options=[{'label': x, 'value': x}\n",
        "                        for x in self.analytics_suite.data['industry'].unique()],\n",
        "                multi=True\n",
        "            ),\n",
        "            html.Label(\"Risk Level\", className=\"mt-3\"),\n",
        "            dcc.RangeSlider(\n",
        "                id='risk-slider',\n",
        "                min=0,\n",
        "                max=100,\n",
        "                step=5,\n",
        "                value=[0, 100]\n",
        "            ),\n",
        "            html.Hr(),\n",
        "            html.H4(\"Quick Actions\"),\n",
        "            dbc.Button(\"Generate Report\", color=\"primary\", className=\"mt-2 w-100\"),\n",
        "            dbc.Button(\"Export Data\", color=\"secondary\", className=\"mt-2 w-100\"),\n",
        "            dbc.Button(\"Refresh\", color=\"info\", className=\"mt-2 w-100\")\n",
        "        ])"
      ],
      "metadata": {
        "id": "MfpHdNkC7y19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        # Optional: Only call setup_callbacks if you have actual callbacks\n",
        "        # self.setup_callbacks()  # Comment or remove this line if no callbacks\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        # Implement callbacks here if needed\n",
        "        pass"
      ],
      "metadata": {
        "id": "nOXdDLx0GflG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "n8pzdbwFrEK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def run_complete_analysis():\n",
        "    try:\n",
        "        # Your analysis logic here\n",
        "        return analytics_suite, insights\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in analysis: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "HYn2olcjrYZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedAnalyticsSuite:\n",
        "    \"\"\"Advanced Analytics Suite with multiple specialized dashboards\"\"\"\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.dashboards = {\n",
        "            'risk': RiskAnalyticsDashboard(analytics_suite),\n",
        "            'bi': BusinessIntelligenceDashboard(analytics_suite),\n",
        "            'ops': OperationsDashboard(analytics_suite),\n",
        "            'viz': AdvancedVisualizationDashboard(analytics_suite)\n",
        "        }\n",
        "\n",
        "    def launch_dashboard(self, dashboard_type='risk'):\n",
        "        \"\"\"Launch specific dashboard\"\"\"\n",
        "        if dashboard_type in self.dashboards:\n",
        "            self.dashboards[dashboard_type].run()\n",
        "        else:\n",
        "            raise ValueError(f\"Dashboard type {dashboard_type} not found\")\n",
        "\n",
        "# Risk Analytics Dashboard\n",
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            dbc.Row([\n",
        "                html.H1(\"Risk Analytics Dashboard\",\n",
        "                        className=\"text-center text-primary mb-4\")\n",
        "            ]),\n",
        "\n",
        "            # Risk Overview Section\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Risk Matrix\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='risk-heatmap')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=8),\n",
        "\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Risk Metrics\"),\n",
        "                        dbc.CardBody([\n",
        "                            html.Div(id='risk-metrics')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=4)\n",
        "            ]),\n",
        "\n",
        "            # Detailed Analysis Section\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Tabs([\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='credit-risk-analysis')\n",
        "                        ], label=\"Credit Risk\"),\n",
        "\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='market-risk-analysis')\n",
        "                        ], label=\"Market Risk\"),\n",
        "\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='operational-risk-analysis')\n",
        "                        ], label=\"Operational Risk\")\n",
        "                    ])\n",
        "                ])\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "# Business Intelligence Dashboard\n",
        "class BusinessIntelligenceDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.BOOTSTRAP],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            dbc.Row([\n",
        "                html.H1(\"Business Intelligence Dashboard\",\n",
        "                        className=\"text-center mb-4\")\n",
        "            ]),\n",
        "\n",
        "            # KPI Section\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    self.create_kpi_card(\"Revenue\", \"revenue-kpi\")\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    self.create_kpi_card(\"Volume\", \"volume-kpi\")\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    self.create_kpi_card(\"Growth\", \"growth-kpi\")\n",
        "                ], width=3),\n",
        "                dbc.Col([\n",
        "                    self.create_kpi_card(\"Risk\", \"risk-kpi\")\n",
        "                ], width=3)\n",
        "            ]),\n",
        "\n",
        "            # Analysis Section\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Trend Analysis\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='trend-analysis')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=8),\n",
        "\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Insights\"),\n",
        "                        dbc.CardBody([\n",
        "                            html.Div(id='automated-insights')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=4)\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "# Operations Dashboard\n",
        "class OperationsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.FLATLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            dbc.Row([\n",
        "                html.H1(\"Operations Dashboard\",\n",
        "                        className=\"text-center mb-4\")\n",
        "            ]),\n",
        "\n",
        "            # Operations Overview\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Active Alerts\"),\n",
        "                        dbc.CardBody([\n",
        "                            html.Div(id='active-alerts')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=6),\n",
        "\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Task Queue\"),\n",
        "                        dbc.CardBody([\n",
        "                            html.Div(id='task-queue')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=6)\n",
        "            ]),\n",
        "\n",
        "            # Performance Metrics\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Performance Metrics\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='performance-metrics')\n",
        "                        ])\n",
        "                    ])\n",
        "                ])\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "# Advanced Visualization Dashboard\n",
        "class AdvancedVisualizationDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.CYBORG],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            dbc.Row([\n",
        "                html.H1(\"Advanced Visualization Dashboard\",\n",
        "                        className=\"text-center mb-4\")\n",
        "            ]),\n",
        "\n",
        "            # 3D Visualizations\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"3D Risk-Volume-Time Analysis\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='3d-analysis')\n",
        "                        ])\n",
        "                    ])\n",
        "                ])\n",
        "            ]),\n",
        "\n",
        "            # Network Analysis\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Client Relationship Network\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='network-analysis')\n",
        "                        ])\n",
        "                    ])\n",
        "                ])\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "# Usage Example\n",
        "def launch_advanced_analytics():\n",
        "    try:\n",
        "        # Initialize base analytics\n",
        "        analytics_suite, insights = run_complete_analysis()\n",
        "\n",
        "        # Create advanced analytics suite\n",
        "        advanced_suite = AdvancedAnalyticsSuite(analytics_suite)\n",
        "\n",
        "        print(\"Available Dashboards:\")\n",
        "        print(\"1. Risk Analytics (risk)\")\n",
        "        print(\"2. Business Intelligence (bi)\")\n",
        "        print(\"3. Operations (ops)\")\n",
        "        print(\"4. Advanced Visualization (viz)\")\n",
        "\n",
        "        dashboard_type = input(\"Enter dashboard type to launch: \")\n",
        "        advanced_suite.launch_dashboard(dashboard_type)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error launching advanced analytics: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    launch_advanced_analytics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM5WGEe8GudW",
        "outputId": "5a2cbc38-6d87-47d1-b19f-c06624474c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error launching advanced analytics: 'RiskAnalyticsDashboard' object has no attribute 'setup_callbacks'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-110-6de85a4d3778>\", line 232, in launch_advanced_analytics\n",
            "    advanced_suite = AdvancedAnalyticsSuite(analytics_suite)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-110-6de85a4d3778>\", line 6, in __init__\n",
            "    'risk': RiskAnalyticsDashboard(analytics_suite),\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-110-6de85a4d3778>\", line 27, in __init__\n",
            "    self.setup_callbacks()\n",
            "    ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'RiskAnalyticsDashboard' object has no attribute 'setup_callbacks'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Layout code\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Define callbacks for the Risk Analytics Dashboard.\"\"\"\n",
        "        # You can leave it empty for now or add your callbacks here\n",
        "        pass\n",
        "\n",
        "\n",
        "class BusinessIntelligenceDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.BOOTSTRAP],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Layout code\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Define callbacks for the Business Intelligence Dashboard.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class OperationsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.FLATLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Layout code\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Define callbacks for the Operations Dashboard.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class AdvancedVisualizationDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.CYBORG],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            # Layout code\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Define callbacks for the Advanced Visualization Dashboard.\"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "DQ3q6Z_FsFvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_callbacks(self):\n",
        "    \"\"\"Define the callbacks for the dashboard.\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "AB_tSiUornsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "        self.setup_callbacks()  # This now refers to the defined method\n",
        "\n",
        "    def setup_layout(self):\n",
        "        self.app.layout = dbc.Container([\n",
        "            dbc.Row([\n",
        "                html.H1(\"Risk Analytics Dashboard\",\n",
        "                        className=\"text-center text-primary mb-4\")\n",
        "            ]),\n",
        "\n",
        "            # Risk Overview Section\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Risk Matrix\"),\n",
        "                        dbc.CardBody([\n",
        "                            dcc.Graph(id='risk-heatmap')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=8),\n",
        "\n",
        "                dbc.Col([\n",
        "                    dbc.Card([\n",
        "                        dbc.CardHeader(\"Risk Metrics\"),\n",
        "                        dbc.CardBody([\n",
        "                            html.Div(id='risk-metrics')\n",
        "                        ])\n",
        "                    ])\n",
        "                ], width=4)\n",
        "            ]),\n",
        "\n",
        "            # Detailed Analysis Section\n",
        "            dbc.Row([\n",
        "                dbc.Col([\n",
        "                    dbc.Tabs([\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='credit-risk-analysis')\n",
        "                        ], label=\"Credit Risk\"),\n",
        "\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='market-risk-analysis')\n",
        "                        ], label=\"Market Risk\"),\n",
        "\n",
        "                        dbc.Tab([\n",
        "                            dcc.Graph(id='operational-risk-analysis')\n",
        "                        ], label=\"Operational Risk\")\n",
        "                    ])\n",
        "                ])\n",
        "            ])\n",
        "        ], fluid=True)\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        \"\"\"Define the callbacks for the dashboard.\"\"\"\n",
        "        # Add your Dash callback definitions here\n",
        "        pass"
      ],
      "metadata": {
        "id": "qdYXJtC2rqdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        # Existing layout code remains the same\n",
        "        pass\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        # Optional method for adding callbacks\n",
        "        pass\n",
        "\n",
        "class BusinessIntelligenceDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.BOOTSTRAP],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        # Existing layout code remains the same\n",
        "        pass\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        # Optional method for adding callbacks\n",
        "        pass\n",
        "\n",
        "class OperationsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.FLATLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        # Existing layout code remains the same\n",
        "        pass\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        # Optional method for adding callbacks\n",
        "        pass\n",
        "\n",
        "class AdvancedVisualizationDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.CYBORG],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        pass\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "t81IW68gHG05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedAnalyticsSuite:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.dashboards = {\n",
        "            'risk': RiskAnalyticsDashboard(analytics_suite),\n",
        "            'bi': BusinessIntelligenceDashboard(analytics_suite),\n",
        "            'ops': OperationsDashboard(analytics_suite),\n",
        "            'viz': AdvancedVisualizationDashboard(analytics_suite)\n",
        "        }\n",
        "\n",
        "    def launch_dashboard(self, dashboard_type='risk'):\n",
        "        if dashboard_type in self.dashboards:\n",
        "            self.dashboards[dashboard_type].run()  # or appropriate method to launch\n",
        "        else:\n",
        "            raise ValueError(f\"Dashboard type {dashboard_type} not found\")"
      ],
      "metadata": {
        "id": "yy8exaJ6HZ7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def launch_advanced_analytics():\n",
        "    try:\n",
        "        # Initialize base analytics\n",
        "        analytics_suite, insights = run_complete_analysis()\n",
        "\n",
        "        # Create advanced analytics suite\n",
        "        advanced_suite = AdvancedAnalyticsSuite(analytics_suite)\n",
        "\n",
        "        print(\"Available Dashboards:\")\n",
        "        print(\"1. Risk Analytics (risk)\")\n",
        "        print(\"2. Business Intelligence (bi)\")\n",
        "        print(\"3. Operations (ops)\")\n",
        "        print(\"4. Advanced Visualization (viz)\")\n",
        "\n",
        "        dashboard_type = input(\"Enter dashboard type to launch: \")\n",
        "        advanced_suite.launch_dashboard(dashboard_type)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error launching advanced analytics: {str(e)}\")\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "ei9kM_txHlXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "import dash\n",
        "import dash_bootstrap_components as dbc\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "\n",
        "def launch_advanced_analytics():\n",
        "    try:\n",
        "        analytics_suite = {}\n",
        "\n",
        "        advanced_suite = AdvancedAnalyticsSuite(analytics_suite)\n",
        "\n",
        "        print(\"Available Dashboards:\")\n",
        "        print(\"1. Risk Analytics (risk)\")\n",
        "        print(\"2. Business Intelligence (bi)\")\n",
        "        print(\"3. Operations (ops)\")\n",
        "        print(\"4. Advanced Visualization (viz)\")\n",
        "\n",
        "        dashboard_type = input(\"Enter dashboard type to launch: \").lower()\n",
        "\n",
        "        # Modify to use .app.run() instead of .run()\n",
        "        if dashboard_type in advanced_suite.dashboards:\n",
        "            dashboard = advanced_suite.dashboards[dashboard_type]\n",
        "            dashboard.app.run_server(debug=True)\n",
        "        else:\n",
        "            raise ValueError(f\"Dashboard type {dashboard_type} not found\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error launching advanced analytics: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "pGdNte0JHsPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RiskAnalyticsDashboard:\n",
        "    def __init__(self, analytics_suite):\n",
        "        self.analytics_suite = analytics_suite\n",
        "        self.app = dash.Dash(__name__,\n",
        "                            external_stylesheets=[dbc.themes.DARKLY],\n",
        "                            suppress_callback_exceptions=True)\n",
        "        self.setup_layout()\n",
        "\n",
        "    def setup_layout(self):\n",
        "        pass\n",
        "\n",
        "    def setup_callbacks(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "fNO1PxzhHyBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uk-1EPzGIVAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}